---
title: "RNN model to predict PAA kinetics"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
# Notebook setup

# By default, only show output when executing code chunks
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(fig.path="figures/", fig.align="center", fig.fullwidth=TRUE, dev = 'png', dpi=600)
# Change working directory to be "Ecoli_RNN", rather than location of notebook
wd.path <- getwd()
if(tail(unlist(strsplit(wd.path,"/")),n=1)=="notebooks") wd.path <- dirname(wd.path)
knitr::opts_knit$set(root.dir = wd.path)
```

# Real time evaluation

```{r PAA samples}
library(xlsx)
library(xts)
# Load raw data from sampling campaign
PAA.PROFILE.DATA <- read.xlsx("data/paa/PAA PROFILE DATA_08-08-19.xlsx", sheetIndex = 1)

# Subset just PAA data
paa <- PAA.PROFILE.DATA[which(PAA.PROFILE.DATA$ANALYSIS_CODE == "PAAR"),]

# Remove erroneous/bad data
paa <- paa[which(paa$COMBINATION_RESULT != "Scratched"),]
paa <- paa[which(!is.na(paa$NUMERIC_RESULT)),]

# Create timestamps
date.time <- data.frame(strptime(paste(as.character(paa$COLLECTION_DATE), as.character(paa$COLLECTION_TIME)), format="%Y-%m-%d %H:%M")
                        , stringsAsFactors = FALSE)

# Create clean data object
paa <- cbind(date.time, 
              as.data.frame(paa$COMMON_NAME, stringsAsFactors = FALSE), 
              as.data.frame(as.numeric(as.character(paa$NUMERIC_RESULT)),
                                  stringsAsFactors = FALSE))
colnames(paa) <- c("date.time", "COMMON_NAME", "NUMERIC_RESULT")
paa <- paa[order(paa[,1]),]
```

```{r PI data}
# Only run this chunk once to download row data
# Load function to import a PI tag
source("src/pi-pull.R")

# Import PI tags
data.parameters <- read.csv("src/data-parameters-north-paa.csv", stringsAsFactors = FALSE)

# Create tag names from PI paths
{
  tag.names <- sapply(data.parameters[,1], function(x) tail(strsplit(tail(strsplit(x,"[\\]")[[1]],n=1),"[|]")[[1]],n=1))

  # For cleanliness, remove path names from list
  names(tag.names) <- NULL
  
  # Rename duplicate tag names by including more characters from the PI path
  duplicates <- names(which(sapply(unique(tag.names), function(x) length(which(x==tag.names)))>1))
  for(i in which(tag.names %in% duplicates)) {
    tag.names[i] <- paste(strsplit(tail(strsplit(data.parameters[i,1],"[\\]")[[1]],n=1),"[|]")[[1]], collapse=" ")
  }
}

# Initialize timestamps from E coli samples
master.timestamps <- paa[,1]

  dir.create("data/paa/north/instant/", showWarnings = FALSE)
  dir.create("data/paa/north/average/", showWarnings = FALSE)
  dir.create("data/paa/north/average-24/", showWarnings = FALSE)
  
# Compile all averaged or raw data (takes 1.5 hours to run serialized, 15 minutes in parallel)
# Initialize parallelization
{
  library(parallel)
  library(doSNOW)
  # detect threads with parallel()
  nThreads<- detectCores(logical = TRUE)
  # Create doSNOW compute cluster
  cluster = makeCluster(nThreads, type = "SOCK")
  # register the cluster
  registerDoSNOW(cluster)
}

library(foreach)
foreach(p=1:length(tag.names),.packages = c("xts", "lubridate", "piwebapi")) %dopar% {
  file <- rep(NA, length(master.timestamps))
  file.avg <- rep(NA, length(master.timestamps))
  file.avg.24 <- rep(NA, length(master.timestamps))

  # Original: Variable averages
  avg <- data.parameters[p,2]
  if(substr(x=avg,start=nchar(avg), stop=nchar(avg))=="m") d <- lubridate::dminutes(x=as.numeric(substr(x=avg, start=1, stop=nchar(avg)-1)))
  if(substr(x=avg,start=nchar(avg), stop=nchar(avg))=="h") d <- lubridate::dhours(x=as.numeric(substr(x=avg, start=1, stop=nchar(avg)-1)))
  
  # Testing: 24h avg for all paramters
  d.24 <- lubridate::dhours(24)

  for(t in 1:length(master.timestamps)) {
    print(paste("Starting timestamp", t))
    start <- as.POSIXct(master.timestamps[t]) - as.numeric(d)
    start.24 <- as.POSIXct(master.timestamps[t]) - as.numeric(d.24)
    end <- as.POSIXct(master.timestamps[t])

    test <- pi.pull(tag=data.parameters[p,1], start=start, end=end, save=FALSE, obj.return = TRUE)
    test.24 <- pi.pull(tag=data.parameters[p,1], start=start.24, end=end, save=FALSE, obj.return = TRUE)
    
    if((nrow(test)==0) || (length(test)==0)) {
      file[t] <- NA
      file.avg[t] <- NA
      file.avg.24[t] <- NA
    } else {

        file[t] <- as.numeric(test[nrow(test),2])

        weights <- as.numeric(difftime(test[,1], start, units="secs"))
        weights.24 <- as.numeric(difftime(test.24[,1], start.24, units="secs"))
        if(nrow(test) > 1) {
          for(i in length(weights):2) weights[i] <- weights[i]-weights[i-1]
          file.avg[t] <- weighted.mean(test[,2], w=weights/sum(weights))
          for(i in length(weights.24):2) weights.24[i] <- weights.24[i]-weights.24[i-1]
          file.avg.24[t] <- weighted.mean(test.24[,2], w=weights.24/sum(weights.24))
        } else {
          file.avg[t] <- as.numeric(test[,2])
          file.avg.24[t] <- as.numeric(test.24[,2])
        }

    }
  }
  write.csv(cbind(master.timestamps, file), file=paste0("data/paa/north/instant/",tag.names[p],".csv"))
  write.csv(cbind(master.timestamps, file.avg), file=paste0("data/paa/north/average/",tag.names[p],".csv"))
  write.csv(cbind(master.timestamps, file.avg.24), file=paste0("data/paa/north/average-24/",tag.names[p],".csv"))
}


# Clean up parallel
{
  # stop cluster and remove clients
  stopCluster(cluster)
  # insert serial backend, otherwise error in repetetive tasks
  registerDoSEQ()
  # clean up a bit.
  invisible(gc); remove(nThreads); remove(cluster);

}
```


# July 2019 Evaluation
Change from PAA setpoint to actual flow-paced concentraiton?
```{r Load data, include=FALSE}
# Load required packages
library(xts)
library(xlsx)

#######################################
# We need three types of data:
# 1. Water qualility
# 2. PAA dose and concentration
# 3. E.coli concentration and removal
#
# It is quickest to load PAA and E.coli 
# and match timestamps to pull process
# water quality data
#######################################

##### PAA ##### 
if("paa.RData" %in% list.files(path="./data/paa/compiled")) {
  load("./data/paa/compiled/paa.RData")
} else {
  # Load raw data from sampling campaign
  PAA.PROFILE.DATA <- read.xlsx("data/paa/PAA PROFILE DATA_08-08-19.xlsx", sheetIndex = 1)
  
  # Subset just PAA data
  paa <- PAA.PROFILE.DATA[which(PAA.PROFILE.DATA$ANALYSIS_CODE == "PAAR"),]
  
  # Remove erroneous/bad data
  paa <- paa[which(paa$COMBINATION_RESULT != "Scratched"),]
  paa <- paa[which(!is.na(paa$NUMERIC_RESULT)),]
  
  # Create timestamps
  date.time <- strptime(paste(as.character(paa$COLLECTION_DATE), as.character(paa$COLLECTION_TIME)), format="%Y-%m-%d %H:%M")
  
  # Create clean data object
  data <- data.frame(date.time, stringsAsFactors = FALSE)
  data <- cbind(data, as.data.frame(paa$COMMON_NAME, stringsAsFactors = FALSE))
  data <- cbind(data, as.data.frame(as.numeric(as.character(paa$NUMERIC_RESULT)),
                                    stringsAsFactors = FALSE))
  colnames(data) <- c("date.time", "COMMON_NAME", "NUMERIC_RESULT")
  data <- data[order(data[,1]),]
  
  # Label sampling campaigns & hour of the day
  sample.count <- vector()
  min <- vector()
  hour <- vector()
  for(i in 2:nrow(data)){
    if(i == 2) {
      last.row <- 1
      sampling.campaign <- 1
    }
    
    if(difftime(data[,"date.time"][i],data[,"date.time"][i-1], units = "mins") > 60) {
      if(i == nrow(data)) {
        sample.count <- c(sample.count, rep(sampling.campaign, length(c(last.row:i))))
        min <- c(min, rep(as.numeric(difftime(as.POSIXct(paste(Sys.Date(), format(data$date.time[i],'%H:%M'))), as.POSIXct(paste(Sys.Date(), "00:00")), units = 'min')), length(c(last.row:(i)))))
        hour <- c(hour, rep(format(round(data$date.time[i], units="hours"), "%H"), length(c(last.row:(i)))))
      } else {
        sample.count <- c(sample.count, rep(sampling.campaign, length(c(last.row:(i-1)))))
        min <- c(min, rep(as.numeric(difftime(as.POSIXct(paste(Sys.Date(), format(data$date.time[i-1],'%H:%M'))), as.POSIXct(paste(Sys.Date(), "00:00")), units = 'min')), length(c(last.row:(i-1)))))
        hour <- c(hour, rep(format(round(data$date.time[i-1], units="hours"), "%H"), length(c(last.row:(i-1)))))
        last.row <- i
        sampling.campaign <- sampling.campaign + 1
      }
    } else {
      if(i == nrow(data)) {
        sample.count <- c(sample.count, rep(sampling.campaign, length(c(last.row:i))))
        hour <- c(hour, rep(format(round(data$date.time[i], units="hours"), "%H"), length(c(last.row:(i)))))
        min <- c(min, rep(as.numeric(difftime(as.POSIXct(paste(Sys.Date(), format(data$date.time[i],'%H:%M'))), as.POSIXct(paste(Sys.Date(), "00:00")), units = 'min')), length(c(last.row:(i)))))
      }
    }
  }
  # data2 <- cbind(data, as.data.frame(sample.count, stringsAsFactors=FALSE), as.data.frame(as.numeric(hour)))
  # colnames(data2)[ncol(data2)] <- "hour.of.day"
  data2 <- cbind(data, as.data.frame(sample.count, stringsAsFactors=FALSE), as.data.frame(min))
  colnames(data2)[ncol(data2)] <- "min.of.day"
  paa <- data2
  save(paa, file="./data/paa/compiled/paa.RData")
}

##### ECOLI #####
if("ecoli.RData" %in% list.files(path="./data/paa/compiled")) {
  load("./data/paa/compiled/ecoli.RData")
} else {
  # Load raw data from sampling campaign
  PAA.PROFILE.DATA <- read.xlsx("data/paa/PAA PROFILE DATA_08-08-19.xlsx", sheetIndex = 1)
  
  # Subset just Ecoli data
  ecoli <- PAA.PROFILE.DATA[which(PAA.PROFILE.DATA$ANALYSIS_CODE == "ECIDX"),]
  
  # Remove irrelevant data
  ecoli <- ecoli[-which(ecoli$COMMON_NAME == "S_PREPAA"),] # Not considering data from the South
  ecoli <- ecoli[-which(ecoli$COMMON_NAME == "N_PREPAA"),] # Not considering data not included in a sampling campaign (i.e., no number precluding label)
  
  # Create timestamps
  date.time <- strptime(paste(as.character(ecoli$COLLECTION_DATE), as.character(ecoli$COLLECTION_TIME)), format="%Y-%m-%d %H:%M")
  
  # Create clean data object
  data <- data.frame(date.time, stringsAsFactors = FALSE)
  data <- cbind(data, as.data.frame(ecoli$COMMON_NAME, stringsAsFactors = FALSE))
  data <- cbind(data, as.data.frame(as.numeric(as.character(ecoli$NUMERIC_RESULT)),
                                    stringsAsFactors = FALSE))
  colnames(data) <- c("date.time", "COMMON_NAME", "NUMERIC_RESULT")
  data <- data[order(data[,1]),]
  
  # Label sampling campaigns
  sample.count <- vector()
  for(i in 2:nrow(data)){
    if(i == 2) {
      last.row <- 1
      sampling.campaign <- 1
    }
    
    if(difftime(data[,"date.time"][i],data[,"date.time"][i-1], units = "mins") > 60) {
      if(i == nrow(data)) {
        sample.count <- c(sample.count, rep(sampling.campaign, length(c(last.row:i))))
      } else {
        sample.count <- c(sample.count, rep(sampling.campaign, length(c(last.row:(i-1)))))
        last.row <- i
        sampling.campaign <- sampling.campaign + 1
      }
    } else {
      if(i == nrow(data)) {
        sample.count <- c(sample.count, rep(sampling.campaign, length(c(last.row:i))))
        }
    }
  }
  data2 <- cbind(data, as.data.frame(sample.count, stringsAsFactors=FALSE))
  
  # Calculate log removal
  log.removal <- vector()
  for(i in unique(data2$sample.count)) {
    experiment <- data2[which(data2$sample.count == i),]
    i.ecoli <- experiment[grepl("N_PREPAA", experiment$COMMON_NAME),"NUMERIC_RESULT"]
    if(length(i.ecoli) == 0) {
      log.removal <- c(log.removal, rep(NA, nrow(experiment)))
    } else {
      exp.removal <- log10(i.ecoli/experiment$NUMERIC_RESULT)
      log.removal <- c(log.removal, exp.removal)
    }
  }
  data3 <- cbind(data2, as.data.frame(log.removal))
  ecoli <- data3
  save(ecoli, file="./data/paa/compiled/ecoli.RData")
}

##### Water quality #####
if("wq.RData" %in% list.files(path="./data/paa/compiled")) {
  load("./data/paa/compiled/wq.RData")
} else {
  # Install and load piwebapi package from Github
  # install.packages("devtools")
  # library(devtools)
  # install_github("rbechalany/PI-Web-API-Client-R")
  library(piwebapi)
  
  # Login information
  useKerberos <- TRUE
  username <- "knewhart"
  password <- ""
  validateSSL <- TRUE
  debug <- TRUE
  piWebApiService <- piwebapi$new("https://pivision/piwebapi", useKerberos, username, password, validateSSL, debug)
  # Go from MT to UTC
  pi.times <- matrix(NA,nrow=length(date.time),ncol=1)
  date.time <- paa$date.time
  for(i in 1:length(date.time)) {
    time.obj <- date.time[i]
    time.obj <- lubridate::with_tz(time.obj, tzone="UTC")
    pi.times[i,1] <- paste0(as.character(format(time.obj,"%Y-%m-%d")),"T",
                            as.character(format(time.obj,"%H:%M:%S")),"Z")
  }
  # Declare with variables/pi tags to pull
  pi.tags <- matrix(c("DIS North Flow", "\\\\applepi\\PAA_North_Plant_Flow",
                      "PAA Setpoint", "\\\\applepi\\PAA_N_Target_Dose",
                      "DIS PAA N Upstream Residual", "\\\\applepi\\AI_K826",
                      "NSEC Aerobic SRT", "\\\\applepi\\ASRT_ASRT_N",
                      "NSEC Effluent NH3", "\\\\applepi\\AI_N501A",
                      "NSEC Effluent NO3", "\\\\applepi\\AI_N501D",
                      "NSEC Effluent OP", "\\\\applepi\\AI_N501F",
                      "NSEC Effluent TSS", "\\\\applepi\\AI-K530N",
                      # "NSEC Effluent NO5", "\\\\applepi\\AI-K570N", # All zeros
                      "NSEC Effluent Flow", "\\\\applepi\\FY-F225"), ncol=2, byrow=TRUE)
  # Pull data
  for(tag in 1:nrow(pi.tags)) {
    pi.points <- piWebApiService$point$getByPath(path=as.character(pi.tags[tag,2]))
    data.holder <- piWebApiService$data$stream$getInterpolatedAtTimes(webId = pi.points$WebId, 
                                                                      time = c(pi.times[,1]))[[2]]
    data.holder <- do.call("rbind", lapply(data.holder, function(x) c(x$Timestamp, x$Value)))
    colnames(data.holder) <- c("Datetime", make.names(pi.tags[tag,1]))
    if(tag==1) all.data <- data.holder
    if(tag>1) {
      all.data <- cbind(all.data, data.holder[,2])
      colnames(all.data)[ncol(all.data)] <- make.names(pi.tags[tag,1])
    }
  }
  # Fix tags from UTC to MT
  date.time <- all.data[,1]
  new.date.time <- .POSIXct(rep(NA, length(date.time)))
  for(i in 1:length(date.time)) {
    time.obj <- paste(strsplit(date.time[i], "T")[[1]][1], 
                      strsplit(strsplit(date.time[i], "T")[[1]][2], "Z")[[1]][1])
    time.obj <- lubridate::with_tz(as.POSIXct(time.obj, tz="UTC"), tzone = Sys.timezone())
    new.date.time[i] <- time.obj
  }
  all.data <- data.frame(all.data)
  all.data[,1] <- new.date.time
  colnames(all.data)[1] <- "date.time"
  wq.data <- all.data
  save(wq.data, file="./data/paa/compiled/wq.RData")
}

##### Merge & Calculate HRT #####
if("paa-wq-ecoli.RData" %in% list.files(path="./data/paa/compiled")) {
  load("./data/paa/compiled/paa-wq-ecoli.RData")
} else {
  paa.wq <- cbind(paa[which(paa$date.time %in% wq.data$date.time),], 
                  wq.data[which(wq.data$date.time %in% paa$date.time),-1])
  # Calculate HRT
  hrt <- matrix(data=NA, nrow=nrow(paa.wq), ncol = 1)
  hrt[grep("NPAA1M", paa.wq$COMMON_NAME)] <- 57.866*as.numeric(as.vector(paa.wq[c(grep("NPAA1M", paa.wq$COMMON_NAME)),"DIS.North.Flow"]))^(-0.959)
  hrt[grep("NPAA10M", paa.wq$COMMON_NAME)] <- 970.18*as.numeric(as.vector(paa.wq[c(grep("NPAA10M", paa.wq$COMMON_NAME)),"DIS.North.Flow"]))^(-0.959)
  hrt[grep("NPAA20M", paa.wq$COMMON_NAME)] <- 1825.3*as.numeric(as.vector(paa.wq[c(grep("NPAA20M", paa.wq$COMMON_NAME)),"DIS.North.Flow"]))^(-0.959)
  hrt[grep("NPAA30M", paa.wq$COMMON_NAME)] <- 2690.3*as.numeric(as.vector(paa.wq[c(grep("NPAA30M", paa.wq$COMMON_NAME)),"DIS.North.Flow"]))^(-0.959)
  paa.wq <- cbind(paa.wq, as.data.frame(hrt, stringsAsFactors = FALSE))
  colnames(paa.wq)[ncol(paa.wq)] <- "HRT (min)"
  
  ##### PAA & WQ & Ecoli #####
  paa.wq.ecoli <- cbind(paa.wq, rep(NA, nrow(paa.wq)))
  paa.wq.ecoli[which(paa.wq.ecoli$date.time %in% ecoli$date.time), ncol(paa.wq.ecoli)] <- 
    ecoli[which(ecoli$date.time %in% paa.wq.ecoli$date.time), "log.removal"]
  colnames(paa.wq.ecoli)[ncol(paa.wq.ecoli)] <- "Log Removal"
  save(paa.wq.ecoli, file="./data/paa/compiled/paa-wq-ecoli.RData")
}


```

```{r Plot PAA and C(t) curve, echo=FALSE, fig.height=2, fig.width=7, message=FALSE, warning=FALSE}
plotCt <- function(experiment) {
# Read in a single sampling event with PAA, HRT, and initial dose
  if(experiment[3,"NUMERIC_RESULT"] == 0) {
    C1=experiment[1,"NUMERIC_RESULT"]
    t1=experiment[1,"HRT (min)"]
    C2=experiment[2,"NUMERIC_RESULT"]
    t2=experiment[2,"HRT (min)"]
    C <- c(C1, C2)
    t <- c(t1, t2)
            
  } else if (experiment[4,"NUMERIC_RESULT"] == 0) {
    C1=experiment[1,"NUMERIC_RESULT"]
    t1=experiment[1,"HRT (min)"]
    C2=experiment[2,"NUMERIC_RESULT"]
    t2=experiment[2,"HRT (min)"]
    C3=experiment[3,"NUMERIC_RESULT"]
    t3=experiment[3,"HRT (min)"]
    C <- c(C1, C2, C3)
    t <- c(t1, t2, t3)
            
  } else if(experiment[4,"NUMERIC_RESULT"] > 0) {
    C1=experiment[1,"NUMERIC_RESULT"]
    t1=experiment[1,"HRT (min)"]
    C2=experiment[2,"NUMERIC_RESULT"]
    t2=experiment[2,"HRT (min)"]
    C3=experiment[3,"NUMERIC_RESULT"]
    t3=experiment[3,"HRT (min)"]
    C4=experiment[4,"NUMERIC_RESULT"]
    t4=experiment[4,"HRT (min)"]
    C <- c(C1,C2,C3,C4)
    t <- c(t1,t2,t3,t4)            
  }
  
  exponential.model <- lm(log(C) ~ t)
  k <- -1*exponential.model$coefficients[2]
  C0 <- exp(as.numeric(exponential.model$coefficients[1]))
  D <- as.numeric(as.vector(experiment[,"PAA.Setpoint"]))[1] - C0
  Ct <- (C0-C0*exp(-k*max(experiment[,"HRT (min)"])))/k # Ct under single exponential curve
  
  plot(y=C,
       x=t,
       ylim=c(0,1.44),
       xlim=c(0,101),
       pch=20,
       xlab="",
       ylab="")
  new.data <- data.frame(x=seq(min(t), max(experiment[,"HRT (min)"]), length.out=100))
  new.data <- cbind(new.data, exp(-k*new.data+log(C0)))
  points(x=new.data[,1],y=new.data[,2], type="l", lty=2)
  polygon(x=c(0,new.data[,1],max(new.data[,1]),0), y=c(C0,new.data[,2],0,0), col="orange", border=NA)
  points(y=C,x=t,pch=20)
  mtext(paste("D =", round(D,2)), side=3,line=-1.1,adj = 0.99)
  mtext(paste("k =", round(k,2)), side=3,line=-2.1,adj = 0.99)
  mtext(paste("CT =", round(Ct,1)), side=3,line=-3.1,adj = 0.99)
  mtext(paste("Trial",i), side=3, line=.25, font=2)
  mtext("PAA (mg/L)", side=2,line=2.5)
  mtext("HRT (min)",side=1,line=2.25)
  
  return(list(Ct, D, k))
}

mat <- matrix(seq(1,3,by=1), nrow=1, ncol=3, byrow=TRUE)
layout(mat=mat, widths=rep(1/ncol(mat),ncol(mat)), heights=rep(1/nrow(mat),nrow(mat)))
par(family="serif", cex=0.9, mar=c(4.25,4.25,1.25,.5))
data <- paa.wq.ecoli
Ct.all <- list()
for(i in unique(data$sample.count)) {
  experiment <- data[which(data$sample.count == i),]
  Ct.all[length(Ct.all)+1] <- plotCt(experiment)
}
```

## Timeseries plot of k and D

## Water quality plot of CT, k, and D
```{r}
n <- sapply(make.names(c("DIS North Flow",
                      "PAA Setpoint",
                      "DIS PAA N Upstream Residual",
                      "NSEC Aerobic SRT",
                      "NSEC Effluent NH3",
                      "NSEC Effluent NO3",
                      "NSEC Effluent OP",
                      "NSEC Effluent TSS",
                      "NSEC Effluent Flow")), 
            function(x) which(colnames(paa.wq.ecoli)==x))
data <- cbind(paa.wq.ecoli[,n], "CT"=unlist(lapply(Ct.all, function(x) x[1])))
data <- apply(data,2,as.numeric)
colnames(data) <- gsub("[.]", " ", colnames(data))

# Store the overall correlation
data.cor <- cor(data)

# Plot the correlation plot with `M`
library(corrplot)
corrplot(data.cor, method="circle")
```


## Real time prediction of CT
```{r include=FALSE}
source("src/rolling-ann.R")
n <- sapply(make.names(c("DIS North Flow",
                      "PAA Setpoint",
                      "DIS PAA N Upstream Residual",
                      "NSEC Aerobic SRT",
                      "NSEC Effluent NH3",
                      "NSEC Effluent NO3",
                      "NSEC Effluent OP",
                      "NSEC Effluent TSS",
                      "NSEC Effluent Flow")), 
            function(x) which(colnames(paa.wq.ecoli)==x))
data <- cbind(paa.wq.ecoli[,n], "CT"=unlist(lapply(Ct.all, function(x) x[1])))
data <- apply(data,2,as.numeric)

test.average <- list()

test.average[[length(test.average)+1]] <- rolling.ann(all.data=data,
                                                      predict.col=which(colnames(data)=="CT"),
                                                      train.obs=ceiling(nrow(data)*.95),
                                                      n_epoch=30000,
                                                      n_nodes=c(9,18),
                                                      scale=TRUE)

test.average[[length(test.average)+1]] <- rolling.ann(all.data=data,
                                                      predict.col=which(colnames(data)=="CT"),
                                                      train.obs=ceiling(nrow(data)*.95),
                                                      n_epoch=30000,
                                                      n_nodes=c(9,18),
                                                      scale=FALSE)

# How goes the scaling?
library(EnvStats)
trans.parameters <- apply(data,2,function(x) {
  # if(min(x) < 0) x <- x+min(x)
  # if(length(which(x==0))>0) x <- x+1 # Zero's present, box-cox can't compute
  b <- boxcox(x, objective.name = "Log-Likelihood", optimize=TRUE, lambda = c(-10,10)) # Use box-cox power transformation
  # x^b$lambda
  b$lambda
})

trans.data <- apply(data,2,function(x) {
  b <- boxcox(x, objective.name = "Log-Likelihood", optimize=TRUE, lambda = c(-10,10)) # Use box-cox power transformation
  x^b$lambda
  # b$lambda
})

test.average[[length(test.average)+1]] <- rolling.ann(all.data=trans.data,
                                                      predict.col=which(colnames(data)=="CT"),
                                                      train.obs=ceiling(nrow(data)*.95),
                                                      n_epoch=30000,
                                                      n_nodes=c(9,18),
                                                      scale=TRUE)

test.average[[length(test.average)+1]] <- rolling.ann(all.data=trans.data,
                                                      predict.col=which(colnames(data)=="CT"),
                                                      train.obs=ceiling(nrow(data)*.95),
                                                      n_epoch=30000,
                                                      n_nodes=c(9,18),
                                                      scale=FALSE)

re.trans.ct <- cbind(test.average[[3]][,"Actual"]^(1/trans.parameters["CT"]),
                     test.average[[3]][,"Prediction"]^(1/trans.parameters["CT"]),
                     test.average[[4]][,"Actual"]^(1/trans.parameters["CT"]),
                     test.average[[4]][,"Prediction"]^(1/trans.parameters["CT"]))
```


```{r include=FALSE}
# Another hidden layer?
test.average <- list()
test.average[[length(test.average)+1]] <- rolling.ann(all.data=data,
                                                      predict.col=which(colnames(data)=="CT"),
                                                      train.obs=ceiling(nrow(data)*.95),
                                                      n_epoch=30000,
                                                      n_nodes=c(9,18,9),
                                                      scale=TRUE)
```


```{r echo=TRUE}
lapply(test.average, function(results) {
  mean(results[,"R2"]) # R2
})

lapply(test.average, function(results) {
  mean((results[,"Prediction"]-results[,"Actual"])^2)^0.5 # Prediction RMSE
})

lapply(test.average, function(results) {
  lims <- range(c(results[,"Actual"], results[,"Prediction"]))
  plot(results[,"Actual"], results[,"Prediction"],
       pch=20, xlab="Actual CT (mg/L min)", ylab="Predicted CT (mg/L min)",
       xlim=lims, ylim=lims)
  abline(a=0,b=1)
})
    
```






# Directly predict PAA concentration at different points
```{r}
library(taRifx)
data <- remove.factors(paa.wq.ecoli)
data[,"COMMON_NAME"] <- sapply(data[,"COMMON_NAME"], function(x) substr(x,3,nchar(x)))
n <- sapply(c("COMMON_NAME", "sample.count","date.time", "Log Removal"), function(x) which(colnames(data)==x))

# Separate by sampling location
data.ls <- lapply(unique(data$COMMON_NAME), function(x) {
  y <- data[which(data$COMMON_NAME == x),-n]
  y <- apply(y,2,as.numeric)
  y
  })
test.ls <- lapply(data.ls, function(x) {rolling.ann(all.data=x,
                                                       predict.col=which(colnames(x)=="NUMERIC_RESULT"),
                                                       train.obs=ceiling(nrow(x)*.95),
                                                       n_epoch=30000,
                                                       n_nodes=c(9,18,9),
                                                       scale=FALSE)
})
```

