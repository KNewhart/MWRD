---
title: "MWRD PAA - Neural Networks Optimization"
subtitle: "Version 4"
author: "Kate Newhart"
output:
  bookdown::word_document2:
    reference_docx: MWRD_PAA_style.docx
    fig_caption: yes
---

```{r Import data, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
rm(list = ls())
library(xts)
library(doSNOW)
library(parallel)
library(neuralnet)

mergeData <- function(list.x, sort.by = 1, average = FALSE) {
  library(xts)
  
  all.data <- do.call(merge, list.x)
  all.data.index <- which(!is.na(all.data[,sort.by]))
  
  for(i in 1:(length(all.data.index)-1)) {
    row.start <- all.data.index[i]
    row.stop <- all.data.index[i+1]
    if(!average) data.locf <- na.locf(all.data[(row.start+1):row.stop,])
    if(average) {
      data.avg <- t(data.frame(sapply(all.data[(row.start+1):row.stop,], function(x) mean(na.omit(x)))))
      rownames(data.avg) <- as.character(index(all.data)[row.stop])

    }
    if (i == 1) {
      if(!average) new.data <- data.frame(data.locf[nrow(data.locf),])
      if(average) new.data <- data.avg
    }
    if (i != 1) {
      if(!average) new.data <- rbind(new.data, data.frame(data.locf[nrow(data.locf),]))
      if(average) new.data <- rbind(new.data, data.avg)
    }
  }
  new.data <- na.omit(new.data)
  new.data.xts <- xts(new.data, order.by = as.POSIXct(rownames(new.data), format = "%Y-%m-%d %H:%M:%S"))
  
  return(new.data.xts)
}


##### PAA Process Data - Grab #####
delta <- intToUtf8(0x0394)
# Daily data
process.data <- readxl::read_excel("data/Copy of PAA Process Data Clean KN.xlsx", 
                                   sheet = "Process Data", skip = 1)
process.data <- process.data[-1,]
n.paa.grab <- xts::xts(apply(process.data[,c(12:17,19:27)], 2, function(x) as.numeric(x)), order.by =  as.POSIXct(as.data.frame(process.data[,18])[,1], format = "%Y-%m-%d %H:%M:%S"))
colnames(n.paa.grab) <- c("PAA Dosing Pump Total Flow (gpm)", #1 
                          "PAA Dose (mg/L)", #2
                          "PAA Setpoint (mg/L)", #3 
                          "Upstream  Residual (mg/L)", #4 
                          # paste0(delta,"PAA (mg/L)"),	#5
                          "deltaPAA (mg/L)", #5
                          "Pre-Disinfection E. coli (MPN/100 mL)",  #6
                          "Effluent Discharge (MGD)", #7
                          "Contact Tank Volume (MG)", #8
                          "Detention Time (min)", #9
                          "Time to Upstream Sample Point (min)", #10
                          "Log Removal (N0/N)", #11
                          "Effluent E. coli (MPN/100 mL)", #12
                          "CT (mg/L*min)", #13
                          "CuT (mg/L*min)", #14
                          "Ambient Temperature")#15
colnames(n.paa.grab) <- stringr::str_replace_all(colnames(n.paa.grab), c(" " = ".", "/" = "." , "-" = "","[(]" = "", "[)]" = "", "[*]"="."))
rm(process.data)


##### October PAA Process Data - Grab #####
oct.paa <- readxl::read_excel("data/Copy of PAA Process Data Clean KN.xlsx", 
                              sheet = "Oct 2 to 15, 2018", range = "A1:V170")[-1,]
n.datetime <- which(colnames(oct.paa) == "Date and Time")
oct.paa.index <- oct.paa[,n.datetime]
oct.paa <- sapply(oct.paa[,-n.datetime], function(x) as.numeric(x))
colnames(oct.paa) <- stringr::str_replace_all(colnames(oct.paa), c(" " = "." , "-" = "" ))
oct.paa <- xts(oct.paa, order.by = oct.paa.index[[1]])

###### North Carbovis Data #####
vis.data <- readxl::read_excel("data/NNE Carbovis Data2.xlsx",
    sheet = "Inst DL Data", col_types = c("date",
        "text", "numeric", "skip", "skip",
        "skip", "numeric", "skip", "skip",
        "skip", "numeric", "skip", "skip",
        "skip", "numeric", "skip", "skip",
        "skip", "numeric", "skip", "skip",
        "skip", "numeric", "skip", "skip",
        "skip", "skip", "numeric", "skip",
        "skip", "skip", "numeric", "skip",
        "skip", "skip", "skip", "numeric",
        "skip", "skip", "skip", "numeric",
        "skip"), skip = 6)
vis.data <- vis.data[which(vis.data[,2] == "Valid"),-2]
colnames(vis.data) <- c("Time", "CODto (mg/L)", "CODto (V)",
                        "TSS (mg/L)", "TSS (V)",
                        "UVT (%)", "UVT (V)",
                        "CODds (mg/L)", "CODds (V)",
                        "SACto (1/m)", "SACto (V)")
vis.data <- xts(vis.data[,-1], order.by = as.POSIXct(as.data.frame(vis.data[,1])[,1], format = "%Y-%m-%d %H-%M-%S"))


##### North Secondary - Online #####
## North secondary online
nsec.online <- as.data.frame(suppressWarnings(readxl::read_excel("data/North Secondary and Disinfection Process Data_20190215.xlsx", sheet = "NSEC Online Data", col_names = FALSE,
    col_types = c("date", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric"), 
    skip = 4)))
nsec.online <- xts(nsec.online[,-1], order.by = nsec.online[,1])
colnames(nsec.online) <- c("NSEC Influent Flow", "NSEC Influent Temp","NSEC Influent NH3","NSEC Influent TSS","NSEC Influent COD",
                           "NSEC CaRRB-1 Centrate Flow","NSEC CaRRB-1 NH3","NSEC CaRRB-3 Centrate Flow","NSEC CaRRB-3 NH3",
                           "GTE Flow","GTE to SSEC Flow","GTE to NSEC Flow",
                           "AB-10 Influent Flow","AB-10 A-Pass Temp","AB-10 A-Pass pH","AB-10 A-Pass DO","AB-10 A-Pass NH3","AB-10 A-Pass NO3","AB-10 B-Pass DO","AB-10 C-Pass pH	AB-10","C-Pass DO","AB-10 C-Pass NH3","AB-10 C-Pass NO3","AB-10 MLSS","AB-10 MLR Flow","Quad 4 RAS Flow","Quad 4 Basins in Service","AB-10 RAS Flow","NSEC Aerobic SRT",
                           "NSEC Effluent NH3","NSEC Effluent NO3","NSEC Effluent OP","NSEC Effluent TSS","NSEC Effluent NO5","NSEC Effluent Flow")


# nsec.online <- nsec.online["2018-11-04/2018-12-01"]
cols2remove <- c("NSEC CaRRB-1 Centrate Flow","NSEC CaRRB-1 NH3","NSEC CaRRB-3 Centrate Flow","NSEC CaRRB-3 NH3","GTE Flow","GTE to SSEC Flow","GTE to NSEC Flow")

nsec.online <- nsec.online[,-sapply(cols2remove, function(x) which(colnames(nsec.online) == x))]

more.nsec <- readxl::read_excel("data/PAA-Ecoli.xlsx", 
                                sheet = "Sheet1", col_types = c("date", 
                                    "numeric", "numeric", "numeric", 
                                    "numeric", "numeric", "numeric", 
                                    "numeric", "numeric", "numeric", 
                                    "numeric", "numeric"))
more.nsec <- xts(more.nsec[,-1], order.by = more.nsec[,1][[1]])
colnames(more.nsec) <- c("PAA Upstream Residual", "PAA Total Flow", "Dis North Flow", 
                         "Temperature NSEC Inf", "ASRT", "NSEC Effluent NH3",
                         "NSEC Effluent NO3","NSEC Effluent OP","NSEC Effluent TSS",
                         "NSEC Effluent NO5","NSEC Effluent Flow")

NNopt <- function(all.data, predict.col.name, percent.train = 0.8, training.index=NULL) {
  ## Prep data
  predict.column <- which(colnames(all.data) == predict.col.name)
  all.data <- na.omit(data.frame(all.data))

  ## Scale data using min-max method
  max <- apply(all.data, 2, max)
  min <- apply(all.data, 2, min)
  scaled.data <- as.data.frame(scale(all.data, center = min, scale = max - min))
  
  ## Create training and test datasets
  if(is.null(training.index)) {
    set.seed(Sys.time())
    training.index <- sample(seq_len(nrow(all.data)), size=(percent.train*nrow(all.data)))
  }
  training.data <- all.data[training.index,]
  testing.data <- all.data[-training.index,]
  training.NN <- scaled.data[training.index,]
  testing.NN <- scaled.data[-training.index,]
  
  fmla <- as.formula(paste0(colnames(all.data)[predict.column],"~",
                            paste(colnames(all.data)[-predict.column], collapse= "+")))
    
  # detect cores with parallel() package
  nCores <- detectCores(logical = FALSE)
  # detect threads with parallel()
  nThreads<- detectCores(logical = TRUE)

  # Create doSNOW compute cluster
  cluster = makeCluster(nThreads, type = "SOCK")
  class(cluster);
  
  # register the cluster
  registerDoSNOW(cluster)
 

  ## Find optimum number of hidden nodes
  results <- foreach::foreach(i = 1:(ncol(all.data)-1), .combine = rbind) %dopar% {
    
  hidden.nodes <- i
  NN <- neuralnet::neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = FALSE)

  ## Predict using NN
  predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.column])
  predict.NN <- (predict.NN$net.result * (max(all.data[,predict.column]) - min(all.data[,predict.column]))) + min(all.data[,predict.column])
  
  # Calculate Root Mean Square Error (RMSE)
  RMSE.NN <- (sum((testing.data[,predict.column] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
  
  data.frame("Hidden Nodes" = hidden.nodes,
             "RMSE" = RMSE.NN)
  }
  
            
  # stop cluster and remove clients
  stopCluster(cluster)
  
  # insert serial backend, otherwise error in repetetive tasks
  registerDoSEQ()
  
  # clean up a bit.
  invisible(gc); remove(nCores); remove(nThreads); remove(cluster); 
  
  ## Build best NN
  hidden.nodes <- min(results[,c("RMSE")])
  hidden.nodes <- which(results[,c("RMSE")] == hidden.nodes)
  hidden.nodes <- as.numeric(results[hidden.nodes,"Hidden.Nodes"])

  NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = FALSE)
  
  ## Predict using NN
  predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.column])
  predict.NN <- (predict.NN$net.result * (max(all.data[,predict.column]) -
                                          min(all.data[,predict.column]))) + 
                                        min(all.data[,predict.column])
  
  # Calculate Root Mean Square Error (RMSE)
  RMSE.NN <- (sum((testing.data[,predict.column] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
  

  return(list("NN" = NN,
              "Actual" = testing.data[,predict.column],
              "Predicted" = predict.NN,
              "RMSE" = RMSE.NN))
} # End of NNopt function

plotTimeseries <- function(data1) {

label1 <- colnames(data1)

r1 <- range(index(data1)[which(!is.na(data1))])[1]
r2 <- range(index(data1)[which(!is.na(data1))])[2]

data2plot <- na.omit(data1)[paste0(r1,"/",r2)]
data2plot <- data.frame(data2plot, row.names = as.character(index(data2plot)))
data2plot <- cbind(data2plot, as.numeric(difftime(as.POSIXct(rownames(data2plot)), as.POSIXct(rownames(data2plot)[1]),units = "days")))

par(mar=c(3.1,4.1,2.1,2.1))
plot(x = data2plot[,ncol(data2plot)], y = data2plot[,1], type = "p", pch = 20, col = "black", xaxt = "n", xlab = "", ylab = "", yaxt="n")
axis(side = 2)
mtext(side = 2, label1, line = 2.5)

# x-axis
axis.ticks <- seq(0,round(data2plot[nrow(data2plot),ncol(data2plot)]), by = 10)
axis.labels <- sapply(axis.ticks, function(x) which(x > data2plot[,ncol(data2plot)]))
axis.labels <- sapply(axis.labels, function(x) x[length(x)])
axis.labels[[1]] <- 1
axis.labels <- as.numeric(unlist(axis.labels))
axis(side = 1, at = axis.ticks, labels = format(as.POSIXct(rownames(data2plot)[axis.labels]), "%m/%d"))
}


plotTwo <- function(data1,data2) {
# data1 <- log(n.paa.grab[,6]) 
# data2 <- nsec.online[,which(colnames(nsec.online) == "NSEC Effluent NO5")]

label1 <- colnames(data1)
label2 <- colnames(data2)
# 
# if (range(index(data1)[which(!is.na(data1))])[1] < range(index(data2)[which(!is.na(data2))])[1]) {
#   r1 <- range(index(data2)[which(!is.na(data2))])[1]
# } else {
#   r1 <- range(index(data1)[which(!is.na(data1))])[1]
# }
# if (range(index(data1)[which(!is.na(data1))])[2] > range(index(data2)[which(!is.na(data2))])[2]) {
#   r2 <- range(index(data2)[which(!is.na(data2))])[2]
# } else {
#   r2 <- range(index(data1)[which(!is.na(data1))])[2]
# }
# 
# data2plot <- na.omit(data1)[paste0(r1,"/",r2)]
# data2plot <- merge(data2plot, data2[paste0(r1,"/",r2)])
data2plot <- merge(data1, data2)
# data2plot <- data2plot[-which(duplicated(index(data2plot))),]
data2plot <- data.frame(data2plot, row.names = as.character(index(data2plot)))
data2plot <- cbind(data2plot, as.numeric(difftime(as.POSIXct(rownames(data2plot)), as.POSIXct(rownames(data2plot)[1]),units = "days")))

par(mar=c(5.1,4.1,2.1,4.1))
x1 <- which(!is.na(data2plot[,1]))
x2 <- which(!is.na(data2plot[,2]))
plot(x = data2plot[x1,3], y = data2plot[x1,1], type = "p", pch = 20, col = "black", xaxt = "n", xlab = "", ylab = "", yaxt="n")
axis(side = 2)
mtext(side = 2, label1, line = 2.5)

par(new = TRUE)
plot(x = data2plot[x2,3], y = data2plot[x2,2], type = "p", pch = 20, col = "red", xaxt = "n", xlab = "", yaxt="n", ylab = "")
axis(side = 4, col.axis = "red")
mtext(side = 4, label2, line = 2.5, col = "red")
# x-axis
axis.ticks <- seq(0,round(data2plot[nrow(data2plot),3]), by = 10)
axis.labels <- sapply(axis.ticks, function(x) which(x > data2plot[,3]))
axis.labels <- sapply(axis.labels, function(x) x[length(x)])
axis.labels[[1]] <- 1
axis.labels <- as.numeric(unlist(axis.labels))
axis(side = 1, at = axis.ticks, labels = format(as.POSIXct(rownames(data2plot)[axis.labels]), "%m/%d"))
}
```

```{r NN procedure, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# NN



all.data <- mergeData(list.x = list(oct.paa,vis.data))
all.data <- na.omit(all.data)
remove.cols.names <- c("PAA.Pump.Total.Flow", "PAA.Set.Point.Dose.Algorithm", "PAA...1.min..Sample","PAA...1.2.Basin.Sampling", "...10" , "Volume.to.1.min..Sample" , "Time.to.1.min..Sample", "Total.Basin.Volume", "DT.of.1.2.Basin", "SPBased.Disinfection.CT",     "CalcBased.Disinfection.CT", "CODto..V.","CODds..V.","TSS..V.", "UVT..V.", "UVT..V.", "SACto..V.")
remove.cols <- sapply(remove.cols.names, function(x) which(colnames(all.data) == x))
all.data <- all.data[,-remove.cols]

x <- data.frame(combn(seq(4,ncol(all.data)),4))
x <- apply(x, 2, function(x) x[order(x)])
# 
# # Random sampling - Node #
# for(i in 1:10) {
#   NN.obj <- NNopt(all.data = all.data[,c(1:3,x[,cols])], predict.col.name = "Initial.PAA.Demand.or.Decay")
#   if(i==1) RMSE.i <- data.frame("Iteration" = i, 
#                                 "Hidden Nodes" = ncol(NN.obj[[1]]$weights[[1]][[1]]),
#                                 "RMSE" = NN.obj[[4]])
#   if(i!=1) RMSE.i <- rbind(RMSE.i, data.frame("Iteration" = i, 
#                                 "Hidden Nodes" = ncol(NN.obj[[1]]$weights[[1]][[1]]),
#                                 "RMSE" = NN.obj[[4]])
#                            )
# }


set.seed(Sys.time())
index <- sample(seq(1,ncol(x)), size=300)
index <- seq(1,ncol(x))

RMSE.i_ls <- list()
start <- Sys.time()
# Start excluding variables
for(jk in 1:5) {
RMSE.i <- data.frame()
for(i in seq(1,ncol(x))) {
  NN.obj <- NNopt(all.data = all.data[,c(1:2,x[,i])], predict.col.name = "Initial.PAA.Demand.or.Decay")
  if(length(RMSE.i) == 0) RMSE.i <- data.frame("Iteration" = i, 
                                # "Col Removed" = colnames(all.data)[-c(1:3,x[,i])],
                                # "Col Kept" = colnames(all.data)[c(1:3,x[,i])],
                                # "Hidden Nodes" = ncol(NN.obj[[1]]$weights[[1]][[1]]),
                                "RMSE" = NN.obj[[4]])
  if(length(RMSE.i) > 0) RMSE.i <- rbind(RMSE.i, data.frame("Iteration" = i, 
                                              # "Col Removed" = colnames(all.data)[-c(1:3,x[,i])],
                                              # "Col Kept" = colnames(all.data)[c(1:3,x[,i])],
                                              # "Hidden Nodes" = ncol(NN.obj[[1]]$weights[[1]][[1]]),
                                              "RMSE" = NN.obj[[4]])
                           )
}

RMSE.i_ls <- c(RMSE.i_ls, list(RMSE.i))
}

RMSE.i_avg <- RMSE.i_ls[[1]]
for (i in 1:nrow(RMSE.i_avg)) {
  RMSE.i_avg[i,2] <- mean(unlist(lapply(RMSE.i_ls, function(x) x[i,2]))) # Average RMSE
}
RMSE.i_avg[,2] <- RMSE.i_avg[,2]
# [,-c(1,3)]
end <- Sys.time()
end-start
# Order results
RMSE.i_avg <- RMSE.i_avg[order(RMSE.i_avg[,2]),]

# 
# ## Plot prediction
# max.val <- max(c(NN.obj[[2]], NN.obj[[3]]))
# min.val <- min(c(NN.obj[[2]], NN.obj[[3]]))
# par(mar=c(3,3,.5,.5), mgp=c(1.75,.5,0))
# plot(x = NN.obj[[2]], y = NN.obj[[3]], 
#      xlim=c(min.val,max.val), ylim=c(min.val,max.val),
#      xlab="Actal PAA Demand", ylab="Predicted PAA Demand", pch=20)
# abline(a=0,b=1,col="blue", lwd=2)
# # text(x=max.val,y=min.val,labels=paste0("RMSE = ",round(RMSE.NN,1)), font=2, adj = 1)
# legend("bottomright", 
#        # inset = c(-.01,.04),
#        legend = c("Observation", "Perfect Fit", paste0("RMSE = ",round(NN.obj[[4]],2))),
#        col = c("black", "blue", NA),
#        pch = c(20,NA, NA),
#        lwd = c(NA,2, NA),
#        bty = "n",
#        xpd=NA,
#        xjust = 1,
#        text.font = 2)
```






```{r Calc D and k}
all.data <- mergeData(list.x = list(oct.paa,vis.data))
all.data <- na.omit(all.data)
r <- paste0(range(index(all.data))[1],"/",range(index(all.data))[2])
all.data <- mergeData(list.x = list(all.data, nsec.online[r,22:28]), average = FALSE)

all.data <- all.data["2018-10-08/"]
## Calculate k
# Repeat once with data to calculate k based on actual C2, then repeat with NN C2
t <- all.data[,"DT.of.1.2.Basin"]
t2 <- all.data[,"DT.of.1.2.Basin"]
t1 <- all.data[,"Time.to.1.min..Sample"]
C2 <- all.data[,"PAA...1.2.Basin.Sampling"]
C1 <- all.data[,"PAA...1.min..Sample"]
C0 <- all.data[,"Pump.Flow.Based.PAA.Dose"]

# Solve for k & D
k.obs <- 1/(t1-t2)*log(C2/C1)
D <- C0-C1*exp(k.obs*t1) # Negative demand????

# Prep data
all.data <- cbind(all.data, k.obs, D)
colnames(all.data)[(ncol(all.data)-1):ncol(all.data)] <- c("k.obs", "D")

remove.cols.names <- c("PAA.Pump.Total.Flow", "PAA.Set.Point.Dose.Algorithm", "PAA...1.min..Sample", "PAA...1.2.Basin.Sampling","Initial.PAA.Demand.or.Decay", "DPAA.Samples", "...10" , "Sample.Time..1_min.","Volume.to.1.min..Sample" ,"DT.of.1.2.Basin", "Time.to.1.min..Sample","Total.Basin.Volume", "SPBased.Disinfection.CT",     "CalcBased.Disinfection.CT", "CODto..V.","TSS..V.", "CODds..V.", "UVT..V.", "SACto..V.")
remove.cols <- sapply(remove.cols.names, function(x) which(colnames(all.data) == x))
all.data <- all.data[,-remove.cols]

NN.obj.k <- NNopt(all.data[,-ncol(all.data)], "k.obs")
NN.obj.D <- NNopt(all.data[,-(ncol(all.data)-1)], "D")

png("images/NN-k.png", units = "in", width = 4.5, height=  4, res = 200)
## Plot prediction
max.val <- max(c(NN.obj.k$Actual, NN.obj.k$Predicted))
min.val <- min(c(NN.obj.k$Actual, NN.obj.k$Predicted))
par(mar=c(3,3,1.5,.5), mgp=c(1.75,.5,0))
plot(x = NN.obj.k$Actual, y = NN.obj.k$Predicted, 
     xlim=c(min.val,max.val), ylim=c(min.val,max.val),
     xlab="Actal", ylab="Predicted", pch=20)
abline(a=0,b=1,col="blue", lwd=2)
# text(x=max.val,y=min.val,labels=paste0("RMSE = ",round(RMSE.NN,1)), font=2, adj = 1)
mtext(text="k", side = 3, font=2)
legend("bottomright", 
       # inset = c(-.01,.04),
       legend = c("Observation", "Perfect Fit", paste0("RMSE = ",round(NN.obj.k$RMSE,2))),
       col = c("black", "blue", NA),
       pch = c(20,NA, NA),
       lwd = c(NA,2, NA),
       bty = "n",
       xpd=NA,
       xjust = 1,
       text.font = 2)
dev.off()

png("images/NN-D.png", units = "in", width = 4.5, height = 4, res = 200)
## Plot prediction
max.val <- max(c(NN.obj.D$Actual, NN.obj.D$Predicted))
min.val <- min(c(NN.obj.D$Actual, NN.obj.D$Predicted))
par(mar=c(3,3,1.5,.5), mgp=c(1.75,.5,0))
plot(x = NN.obj.D$Actual, y = NN.obj.D$Predicted, 
     xlim=c(min.val,max.val), ylim=c(min.val,max.val),
     xlab="Actal", ylab="Predicted", pch=20)
abline(a=0,b=1,col="blue", lwd=2)
# text(x=max.val,y=min.val,labels=paste0("RMSE = ",round(RMSE.NN,1)), font=2, adj = 1)
mtext(text="D", side = 3, font=2)
legend("bottomright", 
       # inset = c(-.01,.04),
       legend = c("Observation", "Perfect Fit", paste0("RMSE = ",round(NN.obj.D$RMSE,2))),
       col = c("black", "blue", NA),
       pch = c(20,NA, NA),
       lwd = c(NA,2, NA),
       bty = "n",
       xpd=NA,
       xjust = 1,
       text.font = 2)
dev.off()
```


```{r Plot C}
data1 <- C0
label1 <- "PAA Concentration (mg/L)"

r1 <- range(index(data1)[which(!is.na(data1))])[1]
r2 <- range(index(data1)[which(!is.na(data1))])[2]

data2plot <- na.omit(data1)[paste0(r1,"/",r2)]
data2plot <- data.frame(data2plot, row.names = as.character(index(data2plot)))
data2plot <- cbind(data2plot, as.numeric(difftime(as.POSIXct(rownames(data2plot)), as.POSIXct(rownames(data2plot)[1]),units = "days")))

png(filename = "images/PAA-time.png", width = 6.5, height = 4, units = "in", res = 200)
par(mar=c(3.1,4.1,2.1,2.1))
plot(x = data2plot[,ncol(data2plot)], y = data2plot[,1], type = "p", pch = 20, col = "black", xaxt = "n", xlab = "", ylab = "", yaxt="n", ylim=c(0,3))
axis(side = 2)
mtext(side = 2, label1, line = 2.5)
  
# x-axis
axis.ticks <- seq(1,nrow(data2plot), length.out = 5)
axis(side = 1, at = data2plot[axis.ticks,ncol(data2plot)], labels = format(as.POSIXct(rownames(data2plot)[axis.ticks]), "%m/%d %H:%M"))

points(data.frame(C1), col = "purple", pch = 20)
points(data.frame(C2), col="blue", pch = 20)

legend(x = data2plot[1,ncol(data2plot)]-.54, y = 3+.12, 
       legend = c("Initial dose", "1-min C", "1/2-basin C"),
       pch = 20, 
       col = c("black", "purple", "blue"),
       # bty = "n", 
       xpd = TRUE)
dev.off()
```



```{r}
k <- -(1/t)*log(C2/(C1))
plot(k)
k_avg <- mean(k)
C2_calc <- C1*exp(-k_avg*t)

## Calculate Ct
Ct_actual <- C1/k_avg*exp(-k_avg*t)
C_actual <- Ct_actual/t

# Predict C1
training.index <- sample(seq_len(nrow(all.data)), size=(0.8*nrow(all.data)))

no.cols <- c("PAA...1.2.Basin.Sampling","Initial.PAA.Demand.or.Decay", "DPAA.Samples",  "Time.to.1.min..Sample", "Sample.Time..1_min.")
no.cols <- sapply(no.cols, function(x) which(colnames(all.data) == x))
NN.obj <- NNopt(all.data = all.data[,-no.cols], predict.col.name = "PAA...1.min..Sample", training.index = training.index)
C1_predict <- NN.obj[[3]] # Prediction

no.cols <- c("PAA...1.min..Sample" ,"Initial.PAA.Demand.or.Decay", "DPAA.Samples",  "Time.to.1.min..Sample", "Sample.Time..1_min.")
no.cols <- sapply(no.cols, function(x) which(colnames(all.data) == x))
NN.obj <- NNopt(all.data = all.data[,-no.cols], predict.col.name = "PAA...1.2.Basin.Sampling", training.index = training.index)
C2_predict <- NN.obj[[3]] # Prediction

k_predict <- -(1/t[-training.index])*log(C2_predict/(C1_predict))
# plot(k);points(k_predict)


Ct_predict <- C1_predict/k_predict*exp(-k_predict*t[-training.index])
plotTimeseries(k_predict)
mean(k_predict)

no.cols <- c("PAA...1.2.Basin.Sampling","PAA...1.min..Sample", "DPAA.Samples",  "Time.to.1.min..Sample", "Sample.Time..1_min.")
no.cols <- sapply(no.cols, function(x) which(colnames(all.data) == x))
NN.obj <- NNopt(all.data = all.data[,-no.cols], predict.col.name = "Initial.PAA.Demand.or.Decay", training.index = training.index)
D_predict <- NN.obj[[3]] # Prediction
D <- all.data[-training.index,"Initial.PAA.Demand.or.Decay"]

png("C2.png")
par(mfrow=c(2,1))
data2plot <- (C2_calc-C2)
colnames(data2plot) <- "Calculated C2 - Actual C2"
plotTimeseries(data2plot)
abline(0,0)
mtext("Decay assuming constant, 1st order kinetics", side = 3)


data2plot <- (C2_predict-C2[-training.index])
colnames(data2plot) <- "Predicted C2 - Actual C2"
plotTimeseries(data2plot)
abline(0,0)
mtext("Neural network decay prediction", side = 3)
dev.off()

png("D.png")
par(mfrow=c(2,1))
data2plot <- (all.data[,"Initial.PAA.Demand.or.Decay"])
colnames(data2plot) <- "D (mg/L)"
plotTimeseries(data2plot)
# abline(0,0)
mtext("Demand", side = 3)
points((D_predict), col="blue", pch=20)

data2plot <- (D_predict-D)
colnames(data2plot) <- "Predicted D - Actual D"
plotTimeseries(data2plot)
abline(0,0)
mtext("Neural network prediction error", side = 3)
dev.off()
```


```{r}
all.data <- mergeData(list.x = list(oct.paa,vis.data))
all.data <- na.omit(all.data)
cols2keep <- c("Initial.PAA.Demand.or.Decay",  "Temp..of.the.Atmos.","Detention.Time",      "CODto..mg.L.",        "TSS..mg.L." 
)
cols2keep <- sapply(cols2keep, function(x) which(colnames(all.data) == x))
NN.obj <- NNopt(all.data = all.data[,cols2keep], predict.col.name = "Initial.PAA.Demand.or.Decay")
```


```{r eval=FALSE, include=FALSE}
# NN
all.data <- mergeData(list.x = list(oct.paa,vis.data))
all.data <- na.omit(all.data)
remove.cols <- sapply(c("CODds..mg.L.", "PAA.Set.Point.Dose.Algorithm", "PAA...1.min..Sample", "PAA...1.2.Basin.Sampling", "DPAA.Samples"), function(x) which(colnames(all.data) == x))
all.data <- all.data[,-remove.cols]
predict.column <- which(colnames(all.data) == "Initial.PAA.Demand.or.Decay")

## Create training and test datasets
set.seed(80)
all.data <- as.data.frame(all.data)
training.index <- sample(seq_len(nrow(all.data)), size=(0.8*nrow(all.data)))
training.data <- all.data[training.index,]
testing.data <- all.data[-training.index,]

## Scale data using min-max method
max <- apply(all.data, 2, max)
min <- apply(all.data, 2, min)
scaled.data <- as.data.frame(scale(all.data, center = min, scale = max - min))

## Fit NN
# install.packages("neuralnet")
library(neuralnet)
training.NN <- scaled.data[training.index,]
testing.NN <- scaled.data[-training.index,]
fmla <- as.formula(paste0(colnames(all.data)[predict.column],"~", paste(colnames(all.data)[-predict.column], collapse= "+")))
```

```{r deltaPAANN, eval=FALSE, fig.cap="Neural network initial PAA demand/decay prediction from Oct 2-15", fig.height=4, fig.width=4, include=FALSE}
for (i in 1:(ncol(all.data)-1)) {
  hidden.nodes <- (ncol(all.data)-i)
  NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = TRUE)

  ## Predict using NN
  predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.column])
  predict.NN <- (predict.NN$net.result * (max(all.data[,predict.column]) - min(all.data[,predict.column]))) + min(all.data[,predict.column])
  
  # Calculate Root Mean Square Error (RMSE)
  RMSE.NN <- (sum((testing.data[,predict.column] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
  
  if(i==1){results <- matrix(c(hidden.nodes,RMSE.NN), ncol=2, dimnames = list(c(NULL), c("Nodes","RMSE")))} else{
    results <- rbind(results, c(hidden.nodes,RMSE.NN))
  }
}

hidden.nodes <- min(results[,c("RMSE")])
hidden.nodes <- which(results[,c("RMSE")] == hidden.nodes)
hidden.nodes <- as.numeric(results[hidden.nodes,c("Nodes")])

NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = TRUE)
# plot(NN)

## Predict using NN
predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.column])
predict.NN <- (predict.NN$net.result * (max(all.data[,predict.column]) - min(all.data[,predict.column]))) + min(all.data[,predict.column])

## Plot prediction
max.val <- max(c(testing.data[,predict.column], predict.NN))
min.val <- min(c(testing.data[,predict.column], predict.NN))
data2plot <- cbind(testing.data[,predict.column], predict.NN)

png("images/PAA_NN.png", units="in", res=2000, width = 6, height = 4)
par(mar=c(3,3,.5,8), mgp=c(1.75,.5,0))
plot(x = data2plot[,1], y = data2plot[,2], 
     # xlim=c(min.val,max.val), ylim=c(min.val,max.val),
     xlab="Actal Initial PAA Demand", ylab="Predicted Initial PAA Demand", pch=20)
abline(a=0,b=1,col="blue", lwd=2)
# text(x=max.val,y=min.val,labels=paste0("RMSE = ",round(RMSE.NN,1)), font=2, adj = 1)
legend("bottomright", 
       # inset = c(-.01,.04),
       legend = c("Observation", "Perfect Fit", paste0("RMSE = ",round(RMSE.NN,2))),
       col = c("black", "blue", NA),
       pch = c(20,NA, NA),
       lwd = c(NA,2, NA),
       bty = "n",
       xpd=NA,
       xjust = 1,
       text.font = 2)
text(do.call(paste0, as.list(paste0(colnames(testing.data), "\n"))), x = max(data2plot[,1])+.015, y = 0.55, xpd=NA, pos=4, cex=.7)
dev.off()

plot(NN)

```

Figure \@ref(fig:deltaPAANN) BOO YAH

```{r eval=FALSE, include=FALSE}
# NN
RMSE.NN.org <- RMSE.NN
all.data <- mergeData(list.x = list(oct.paa,vis.data))
all.data <- na.omit(all.data)
remove.cols.names <- c("PAA.Pump.Total.Flow", "PAA.Set.Point.Dose.Algorithm", "PAA...1.min..Sample","PAA...1.2.Basin.Sampling", "...10" , "Volume.to.1.min..Sample" , "Time.to.1.min..Sample", "Total.Basin.Volume", "DT.of.1.2.Basin", "SPBased.Disinfection.CT",     "CalcBased.Disinfection.CT", "CODto..V.","TSS..V.", "UVT..V.", "UVT..V.", "SACto..V.")
remove.cols <- sapply(remove.cols.names, function(x) which(colnames(all.data) == x))
all.data <- all.data[,-remove.cols]


predict.cols.names <- c("Initial.PAA.Demand.or.Decay", "DPAA.Samples")
predict.cols <- sapply(predict.cols.names, function(x) which(colnames(all.data) == x))

## Create training and test datasets
set.seed(80)
all.data <- as.data.frame(all.data)
training.index <- sample(seq_len(nrow(all.data)), size=(0.8*nrow(all.data)))
training.data <- all.data[training.index,]
testing.data <- all.data[-training.index,]

## Scale data using min-max method
max <- apply(all.data, 2, max)
min <- apply(all.data, 2, min)
scaled.data <- as.data.frame(scale(all.data, center = min, scale = max - min))

## Fit NN
# install.packages("neuralnet")
library(neuralnet)
training.NN <- scaled.data[training.index,]
testing.NN <- scaled.data[-training.index,]

for (predictor in 1:length(predict.cols)) {
  

fmla <- as.formula(paste0(colnames(all.data)[predict.cols[predictor]],"~", paste(colnames(all.data)[-predict.cols], collapse= "+")))

for (i in 1:(ncol(all.data)-1)) {
  hidden.nodes <- (ncol(all.data)-i)
  NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = TRUE)

  ## Predict using NN
  predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.column])
  predict.NN <- (predict.NN$net.result * (max(all.data[,predict.column]) - min(all.data[,predict.column]))) + min(all.data[,predict.column])
  
  # Calculate Root Mean Square Error (RMSE)
  RMSE.NN <- (sum((testing.data[,predict.column] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
  
  if(i==1){results <- matrix(c(hidden.nodes,RMSE.NN), ncol=2, dimnames = list(c(NULL), c("Nodes","RMSE")))} else{
    results <- rbind(results, c(hidden.nodes,RMSE.NN))
  }
}

hidden.nodes <- min(results[,c("RMSE")])
hidden.nodes <- which(results[,c("RMSE")] == hidden.nodes)
hidden.nodes <- as.numeric(results[hidden.nodes,c("Nodes")])

NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = TRUE)
# plot(NN)

## Predict using NN
predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.column])
predict.NN <- (predict.NN$net.result * (max(all.data[,predict.column]) - min(all.data[,predict.column]))) + min(all.data[,predict.column])

## Plot prediction
max.val <- max(c(testing.data[,predict.column], predict.NN))
min.val <- min(c(testing.data[,predict.column], predict.NN))
data2plot <- cbind(testing.data[,predict.column], predict.NN)

png(paste0("images/PAA_NN_",colnames(all.data)[predict.cols[predictor]],".png"), units="in", res=2000, width = 4, height = 4)
par(mar=c(3,3,2,8), mgp=c(1.75,.5,0))
plot(x = data2plot[,1], y = data2plot[,2]
     # , xlim=c(min.val,max.val), ylim=c(min.val,max.val),
     , xlab="Actal", ylab="Predicted"
     , pch=20
     , main = colnames(all.data)[predict.cols[predictor]]
     )
abline(a=0,b=1,col="blue", lwd=2)
# text(x=max.val,y=min.val,labels=paste0("RMSE = ",round(RMSE.NN,1)), font=2, adj = 1)
legend("bottomright", 
       # inset = c(-.01,.04),
       legend = c("Observation", "Perfect Fit", paste0("RMSE = ",round(RMSE.NN,2))),
       col = c("black", "blue", NA),
       pch = c(20,NA, NA),
       lwd = c(NA,2, NA),
       bty = "n",
       xpd=NA,
       xjust = 1,
       text.font = 2)
text(do.call(paste0, as.list(paste0(colnames(testing.data), "\n"))), x = max(data2plot[,1])+.015, y = 0.55, xpd=NA, pos=4, cex=.7)
dev.off()
}




# for(i in 1:10) {
# 
# # if(ncol(NN$weights[[1]][[1]]) == 2) cols2remove <- c(which(abs(NN$weights[[1]][[1]][,1]) == min(abs(NN$weights[[1]][[1]][,1]))), which(abs(NN$weights[[1]][[1]][,2]) == min(abs(NN$weights[[1]][[1]][,2]))))
# # if(ncol(NN$weights[[1]][[1]]) == 1) cols2remove <- which(abs(NN$weights[[1]][[1]][,1]) == min(abs(NN$weights[[1]][[1]][,1])))
# cols2remove <- apply(NN$weights[[1]][[1]],2,function(x) which(abs(x) == min(abs(x))))
# all.data <- all.data[,-cols2remove]
# }

```




```{r October PAA Grab Sample - NN model, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# NN
all.data <- oct.paa
r <- paste0(range(index(all.data))[1],"/",range(index(all.data))[2])
all.data <- mergeData(list.x = list(all.data,vis.data[r]))
all.data <- mergeData(list.x = list(all.data, nsec.online[r,22:28]), average = FALSE)

# all.data <- na.omit(all.data)
# zero.rows <- unlist(apply(all.data, 2, function(x) which(x == 0)))

remove.cols.names <- c("PAA.Pump.Total.Flow", "PAA.Set.Point.Dose.Algorithm", "PAA...1.min..Sample","PAA...1.2.Basin.Sampling", "...10" , "Volume.to.1.min..Sample" , "Time.to.1.min..Sample", "Total.Basin.Volume", "DT.of.1.2.Basin", "Sample.Time..1_min.", "SPBased.Disinfection.CT", "CalcBased.Disinfection.CT", "CODto..V.", "TSS..V.", "UVT..V.", "CODds..V.", "SACto..V.", "N..Eff..TSS.Conc.")
remove.cols <- sapply(remove.cols.names, function(x) which(colnames(all.data) == x))
all.data <- all.data[,-remove.cols]

predict.cols.names <- c("Initial.PAA.Demand.or.Decay", "DPAA.Samples")
predict.cols <- sapply(predict.cols.names, function(x) which(colnames(all.data) == x))

## Create training and test datasets
set.seed(80)
all.data <- as.data.frame(all.data)
training.index <- sample(seq_len(nrow(all.data)), size=(0.8*nrow(all.data)))
training.data <- all.data[training.index,]
testing.data <- all.data[-training.index,]

## Scale data using min-max method
max <- apply(all.data, 2, max)
min <- apply(all.data, 2, min)
scaled.data <- as.data.frame(scale(all.data, center = min, scale = max - min))

## Fit NN
# install.packages("neuralnet")
library(neuralnet)
training.NN <- scaled.data[training.index,]
testing.NN <- scaled.data[-training.index,]

# for (predictor in 1:length(predict.cols)) {
predictor <- 1

fmla <- as.formula(paste0(colnames(all.data)[predict.cols[predictor]],"~", paste(colnames(all.data)[-predict.cols], collapse= "+")))

for (j in 1:(ncol(all.data[-predict.cols])-1)) {
  hidden.nodes <- (ncol(all.data[-predict.cols])-j)
  NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = FALSE)

  ## Predict using NN
  predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.cols])
  predict.NN <- (predict.NN$net.result * (max(all.data[,predict.cols[predictor]]) - min(all.data[,predict.cols[predictor]]))) + min(all.data[,predict.cols[predictor]])
  
  # Calculate Root Mean Square Error (RMSE)
  RMSE.NN <- (sum((testing.data[,predict.cols[predictor]] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
  
  if(j==1){results <- matrix(c(hidden.nodes,RMSE.NN), ncol=2, dimnames = list(c(NULL), c("Nodes","RMSE")))} else{
    results <- rbind(results, c(hidden.nodes,RMSE.NN))
  }
}

# Use # of nodes with lowest RMSE
hidden.nodes <- min(results[,c("RMSE")])
hidden.nodes <- which(results[,c("RMSE")] == hidden.nodes)
hidden.nodes <- as.numeric(results[hidden.nodes,c("Nodes")])
# Retrain with optimum number of nodes
NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = FALSE)
# plot(NN)

## Predict using NN
predict.NN.colnames <- colnames(testing.NN[,-predict.cols])
predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.cols])

## Re-scale
predict.NN <- (predict.NN$net.result * (max(all.data[,predict.cols[predictor]]) - min(all.data[,predict.cols[predictor]]))) + min(all.data[,predict.cols[predictor]])

## Plot prediction
max.val <- max(c(testing.data[,predict.cols[predictor]], predict.NN))
min.val <- min(c(testing.data[,predict.cols[predictor]], predict.NN))
data2plot <- cbind(testing.data[,predict.cols[predictor]], predict.NN)

png(paste0("images/PAA_NN_",colnames(all.data)[predict.cols[predictor]],".png"), units="in", res=2000, width = 5, height = 4)
par(mar=c(3,3,2,8), mgp=c(1.75,.5,0))
plot(x = data2plot[,1], y = data2plot[,2]
     , xlim=c(min.val,max.val), ylim=c(min.val,max.val)
     , xlab="Actal", ylab="Predicted"
     , pch=20
     , main = stringr::str_replace_all(colnames(all.data)[predict.cols[predictor]], c("[.]" = " "))
     )
abline(a=0,b=1,col="blue", lwd=2)

legend("bottomright", 
       inset = c(-.55,-.23),
       legend = c("Observation", "Perfect Fit", paste0("RMSE = ",round(RMSE.NN,2))),
       col = c("black", "blue", NA),
       pch = c(20,NA, NA),
       lwd = c(NA,2, NA),
       bty = "n",
       xpd=NA,
       xjust = 1,
       text.font = 2)

text(do.call(paste0, as.list(paste0(stringr::str_replace_all(predict.NN.colnames, c("[.][.]" = " ", "[.]" = " ")), "\n"))), x = max.val+max.val*.015, y = max.val-min.val, xpd=NA, pos=4, cex=.7)
dev.off()




predictor <- 2

fmla <- as.formula(paste0(colnames(all.data)[predict.cols[predictor]],"~", paste(colnames(all.data)[-predict.cols], collapse= "+")))

for (j in 1:(ncol(all.data[-predict.cols])-1)) {
  hidden.nodes <- (ncol(all.data[-predict.cols])-j)
  NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = FALSE)

  ## Predict using NN
  predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.cols])
  predict.NN <- (predict.NN$net.result * (max(all.data[,predict.cols[predictor]]) - min(all.data[,predict.cols[predictor]]))) + min(all.data[,predict.cols[predictor]])
  
  # Calculate Root Mean Square Error (RMSE)
  RMSE.NN <- (sum((testing.data[,predict.cols[predictor]] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
  
  if(j==1){results <- matrix(c(hidden.nodes,RMSE.NN), ncol=2, dimnames = list(c(NULL), c("Nodes","RMSE")))} else{
    results <- rbind(results, c(hidden.nodes,RMSE.NN))
  }
}

# Use # of nodes with lowest RMSE
hidden.nodes <- min(results[,c("RMSE")])
hidden.nodes <- which(results[,c("RMSE")] == hidden.nodes)
hidden.nodes <- as.numeric(results[hidden.nodes,c("Nodes")])
# Retrain with optimum number of nodes
NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = FALSE)
# plot(NN)

## Predict using NN
predict.NN.colnames <- colnames(testing.NN[,-predict.cols])
predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.cols])
predict.NN.scaled <- predict.NN

## Re-scale
predict.NN <- (predict.NN$net.result * (max(all.data[,predict.cols[predictor]]) - min(all.data[,predict.cols[predictor]]))) + min(all.data[,predict.cols[predictor]])

## Plot prediction
max.val <- max(c(testing.data[,predict.cols[predictor]], predict.NN))
min.val <- min(c(testing.data[,predict.cols[predictor]], predict.NN))
data2plot <- cbind(testing.data[,predict.cols[predictor]], predict.NN)

png(paste0("images/PAA_NN_",colnames(all.data)[predict.cols[predictor]],".png"), units="in", res=2000, width = 5, height = 4)
par(mar=c(3,3,2,8), mgp=c(1.75,.5,0))
plot(x = data2plot[,1], y = data2plot[,2]
     , xlim=c(min.val,max.val), ylim=c(min.val,max.val)
     , xlab="Actal", ylab="Predicted"
     , pch=20
     , main = stringr::str_replace_all(colnames(all.data)[predict.cols[predictor]], c("[.]" = " "))
     )
abline(a=0,b=1,col="blue", lwd=2)

legend("bottomright", 
       inset = c(-.55,-.23),
       legend = c("Observation", "Perfect Fit", paste0("RMSE = ",round(RMSE.NN,2))),
       col = c("black", "blue", NA),
       pch = c(20,NA, NA),
       lwd = c(NA,2, NA),
       bty = "n",
       xpd=NA,
       xjust = 1,
       text.font = 2)

text(do.call(paste0, as.list(paste0(stringr::str_replace_all(predict.NN.colnames, c("[.][.]" = " ", "[.]" = " ")), "\n"))), x = max.val+max.val*.015, y = max.val-2*min.val, xpd=NA, pos=4, cex=.7)
dev.off()
# }
```


```{r Lets mess with flowrates}
## For one set of conditions
for(r in 1:nrow(testing.NN)) {
  
## Let's change the scaled flowrates
testing.data <- testing.NN[r,-predict.cols]
for(i in 0:100) {
  if(i > 0) testing.data <- rbind(testing.data, testing.NN[r,-predict.cols])
  testing.data[nrow(testing.data),1] <- i*.01
}

## Predict scaled delta-PAA
predict.NN <-  neuralnet::compute(NN, testing.data)

## Re-scale to Delta-PAA
predict.NN <- (predict.NN$net.result * (max(all.data[,predict.cols[predictor]]) - min(all.data[,predict.cols[predictor]]))) + min(all.data[,predict.cols[predictor]])
# PAA Dose
predictor.flow <- (testing.data[,1] * (max(all.data[,1]) - min(all.data[,1]))) + min(all.data[,1])
# 1/2 basin PAA
# calc.final <- predictor.flow - predict.NN # NO


if(r==1) plot.data <- cbind(predictor.flow, predict.NN)
if(r>1) plot.data <- cbind(plot.data, predict.NN)
}

plot.min <- min(apply(plot.data[,2:ncol(plot.data)],2,min))
plot.max <- max(apply(plot.data[,2:ncol(plot.data)],2,max))

png("images/flow_variance_NN.png", units = "in", res = 2000, width = 5, height = 3.5)
par(cex=1, mar=c(3,3,.5,.5), mgp=c(1.75,.5,0))
plot(plot.data[,1:2], col="white", xlab = "C0 (mg/L PAA) - Predictor", ylab = "dC (mg/L PAA) - Response", ylim = c(plot.min,plot.max))
for(i in 2:ncol(plot.data)) {
  xspline(x=plot.data[,1], plot.data[,i], lty=2)
}
legend("topleft",
       legend = c("Various Environmental Conditions"),
       lty = c(2)
       )
dev.off()
```


```{r Comparison to online PAA - NN model, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# NN
all.data <- vis.data
data2 <- more.nsec[-which(is.na(more.nsec[,2])),]
data2 <- data2[-which(data2[,1] < 0.1),]
data2 <- data2[-which(data2[,1] > 2.5),]
r <- paste0(range(index(all.data))[1],"/",range(index(all.data))[2])
r <- paste0(range(index(data2[r]))[1],"/",
            range(index(data2[r]))[2])
all.data <- mergeData(list.x = list(data2[r],all.data[r])) 

remove.cols.names <- c("CODto..V.", "TSS..V.", "UVT..V.", "CODds..V.", "SACto..V.")
remove.cols <- sapply(remove.cols.names, function(x) which(colnames(all.data) == x))
all.data <- all.data[,-remove.cols]

predict.cols.names <- c("PAA.Upstream.Residual")
predict.cols <- sapply(predict.cols.names, function(x) which(colnames(all.data) == x))

## Create training and test datasets
set.seed(80)
all.data <- as.data.frame(all.data)
all.data <- model.matrix(as.formula(paste0("~",paste(colnames(all.data),collapse="+"))), data=all.data)[,-1]
training.index <- sample(seq_len(nrow(all.data)), size=(0.8*nrow(all.data)))
training.data <- all.data[training.index,]
testing.data <- all.data[-training.index,]

## Scale data using min-max method
max <- apply(all.data, 2, max)
min <- apply(all.data, 2, min)
scaled.data <- as.data.frame(scale(all.data, center = min, scale = max - min))

## Fit NN
# install.packages("neuralnet")
library(neuralnet)
training.NN <- scaled.data[training.index,]
testing.NN <- scaled.data[-training.index,]

# for (predictor in 1:length(predict.cols)) {
predictor <- 1

fmla <- as.formula(paste0(colnames(all.data)[predict.cols[predictor]],"~", paste(colnames(all.data)[-predict.cols], collapse= "+")))

# for (j in 1:(ncol(all.data[-predict.cols])-1)) {
for (j in seq(1,(ncol(all.data[,-predict.cols])-1),2)) {
  print(j)
  hidden.nodes <- j
  NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = FALSE)

  ## Predict using NN
  predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.cols])
  predict.NN <- (predict.NN$net.result * (max(all.data[,predict.cols[predictor]]) - min(all.data[,predict.cols[predictor]]))) + min(all.data[,predict.cols[predictor]])
  
  # Calculate Root Mean Square Error (RMSE)
  RMSE.NN <- (sum((testing.data[,predict.cols[predictor]] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
  
  if(j==1){results <- matrix(c(hidden.nodes,RMSE.NN), ncol=2, dimnames = list(c(NULL), c("Nodes","RMSE")))} else{
    results <- rbind(results, c(hidden.nodes,RMSE.NN))
  }
  print(RMSE.NN)
}

# Use # of nodes with lowest RMSE
hidden.nodes <- min(results[,c("RMSE")])
hidden.nodes <- which(results[,c("RMSE")] == hidden.nodes)
hidden.nodes <- as.numeric(results[hidden.nodes,c("Nodes")])
# Retrain with optimum number of nodes
hidden.nodes <- 2
start.time <- Sys.time()
NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = FALSE)
end.time <- Sys.time()
end.time - start.time


## Predict using NN
predict.NN.colnames <- colnames(testing.NN[,-predict.cols])
predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.cols])
# predict.NN <- neuralnet::prediction(NN, testing.NN[,-predict.cols])

## Re-scale
predict.NN <- (predict.NN$net.result * (max(all.data[,predict.cols[predictor]]) - min(all.data[,predict.cols[predictor]]))) + min(all.data[,predict.cols[predictor]])

## Plot prediction
max.val <- max(c(testing.data[,predict.cols[predictor]], predict.NN))
min.val <- min(c(testing.data[,predict.cols[predictor]], predict.NN))
data2plot <- cbind(testing.data[,predict.cols[predictor]], predict.NN)

png(paste0("images/onlinePAA_NN_",colnames(all.data)[predict.cols[predictor]],"_clean_",hidden.nodes,".png"), units="in", res=2000, width = 5, height = 4)
par(mar=c(3,3,2,8), mgp=c(1.75,.5,0))
plot(x = data2plot[,1], y = data2plot[,2]
     , xlim=c(min.val,max.val), ylim=c(min.val,max.val)
     , xlab="Actal", ylab="Predicted"
     , pch=20
     , main = stringr::str_replace_all(colnames(all.data)[predict.cols[predictor]], c("[.]" = " "))
     )
abline(a=0,b=1,col="blue", lwd=2)

legend("bottomright", 
       inset = c(-.55,-.23),
       legend = c("Observation", "Perfect Fit", paste0("RMSE = ",round(RMSE.NN,2))),
       col = c("black", "blue", NA),
       pch = c(20,NA, NA),
       lwd = c(NA,2, NA),
       bty = "n",
       xpd=NA,
       xjust = 1,
       text.font = 2)

text(do.call(paste0, as.list(paste0(stringr::str_replace_all(predict.NN.colnames, c("[.][.]" = " ", "[.]" = " ")), "\n"))), x = max.val+max.val*.015, y = max.val-min.val-max.val*.02, xpd=NA, pos=4, cex=.7)
dev.off()

# }
```


```{r E.coli take two}
library(readxl)
library(xts)


ecoli <- readxl::read_excel("data/PAA-Ecoli.xlsx", 
                                sheet = "Sheet2")
ecoli <- list(xts(na.omit(ecoli[,2][[1]]), order.by = na.omit(ecoli[,1][[1]])),
              xts(na.omit(ecoli[,4][[1]]), order.by = na.omit(ecoli[,3][[1]])))

ecoli <- mergeData(ecoli)
colnames(ecoli) <- c("Pre-dis E.coli", "Post-dis E.coli")






vis.data <- readxl::read_excel("data/NNE Carbovis Data2.xlsx",
                               sheet = "Inst DL Data", col_types = c("date",
                                                                     "text", "numeric", "skip", "skip",
                                                                     "skip", "numeric", "skip", "skip",
                                                                     "skip", "numeric", "skip", "skip",
                                                                     "skip", "numeric", "skip", "skip",
                                                                     "skip", "numeric", "skip", "skip",
                                                                     "skip", "numeric", "skip", "skip",
                                                                     "skip", "skip", "numeric", "skip",
                                                                     "skip", "skip", "numeric", "skip",
                                                                     "skip", "skip", "skip", "numeric",
                                                                     "skip", "skip", "skip", "numeric",
                                                                     "skip"), skip = 6)
vis.data <- vis.data[which(vis.data[,2] == "Valid"),-2]
colnames(vis.data) <- c("Time", "CODto (mg/L)", "CODto (V)",
                        "TSS (mg/L)", "TSS (V)",
                        "UVT (%)", "UVT (V)",
                        "CODds (mg/L)", "CODds (V)",
                        "SACto (1/m)", "SACto (V)")
vis.data <- xts(vis.data[,-1], order.by = as.POSIXct(as.data.frame(vis.data[,1])[,1], format = "%Y-%m-%d %H-%M-%S"))








all.data <- vis.data
data2 <- ecoli
r <- paste0(range(index(all.data))[1],"/",range(index(all.data))[2])
r <- paste0(range(index(data2[r]))[1],"/",
            range(index(data2[r]))[2])
all.data <- mergeData(list.x = list(data2[r],all.data[r])) 

remove.cols.names <- c("CODto..V.", "TSS..V.", "UVT..V.", "CODds..V.", "SACto..V.")
remove.cols <- sapply(remove.cols.names, function(x) which(colnames(all.data) == x))
all.data <- all.data[,-remove.cols]


more.nsec <- readxl::read_excel("data/PAA-Ecoli-2.xlsx", 
                                sheet = "Sheet1", col_types = c("date", 
                                                                "numeric", "numeric", "numeric", 
                                                                "numeric", "numeric", "numeric", 
                                                                "numeric", "numeric", "numeric", 
                                                                "numeric", "numeric", "numeric"))
more.nsec <- xts(more.nsec[,-1], order.by = more.nsec[,1][[1]])
colnames(more.nsec) <- c("PAA Upstream Residual", "PAA Total Flow", "Dis North Flow", 
                         "Temperature NSEC Inf", "ASRT", "NSEC Effluent NH3",
                         "NSEC Effluent NO3","NSEC Effluent OP","NSEC Effluent TSS",
                         "NSEC Effluent NO5","NSEC Effluent Flow", "AB-10 RAS")



data2 <- all.data
all.data <- more.nsec
r <- paste0(range(index(all.data))[1],"/",range(index(all.data))[2])
r <- paste0(range(index(data2[r]))[1],"/",
            range(index(data2[r]))[2])
all.data <- mergeData(list.x = list(data2[r],all.data[r])) 











predict.cols.names <- c("Pre.dis.E.coli", "Post.dis.E.coli")
predict.cols <- sapply(predict.cols.names, function(x) which(colnames(all.data) == x))
all.data[,predict.cols] <- log(all.data[,predict.cols])

## Create training and test datasets
set.seed(80)
all.data <- as.data.frame(all.data)
training.index <- sample(seq_len(nrow(all.data)), size=(0.8*nrow(all.data)))
training.data <- all.data[training.index,]
testing.data <- all.data[-training.index,]

## Scale data using min-max method
max <- apply(all.data, 2, max)
min <- apply(all.data, 2, min)
scaled.data <- as.data.frame(scale(all.data, center = min, scale = max - min))

## Fit NN
# install.packages("neuralnet")
library(neuralnet)
training.NN <- scaled.data[training.index,]
testing.NN <- scaled.data[-training.index,]

for (predictor in 1:length(predict.cols)) {
# predictor <- 1

fmla <- as.formula(paste0(colnames(all.data)[predict.cols[predictor]],"~", paste(colnames(all.data)[-predict.cols], collapse= "+")))

for (j in 1:(ncol(all.data[-predict.cols])-1)) {
  hidden.nodes <- j
  NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = FALSE)
  
  ## Predict using NN
  predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.cols])
  predict.NN <- (predict.NN$net.result * (max(all.data[,predict.cols[predictor]]) - min(all.data[,predict.cols[predictor]]))) + min(all.data[,predict.cols[predictor]])
  
  # Calculate Root Mean Square Error (RMSE)
  RMSE.NN <- (sum((testing.data[,predict.cols[predictor]] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
  
  if(j==1){results <- matrix(c(hidden.nodes,RMSE.NN), ncol=2, dimnames = list(c(NULL), c("Nodes","RMSE")))} else{
    results <- rbind(results, c(hidden.nodes,RMSE.NN))
  }
}

# Use # of nodes with lowest RMSE
hidden.nodes <- min(results[,c("RMSE")])
hidden.nodes <- which(results[,c("RMSE")] == hidden.nodes)
hidden.nodes <- as.numeric(results[hidden.nodes,c("Nodes")])
# Retrain with optimum number of nodes
NN <- neuralnet(fmla, training.NN, hidden = hidden.nodes, linear.output = TRUE)
# plot(NN)

## Predict using NN
predict.NN.colnames <- colnames(testing.NN[,-predict.cols])
predict.NN <-  neuralnet::compute(NN, testing.NN[,-predict.cols])

## Re-scale
predict.NN <- (predict.NN$net.result * (max(all.data[,predict.cols[predictor]]) - min(all.data[,predict.cols[predictor]]))) + min(all.data[,predict.cols[predictor]])

## Plot prediction
max.val <- max(c(testing.data[,predict.cols[predictor]], predict.NN))
min.val <- min(c(testing.data[,predict.cols[predictor]], predict.NN))
data2plot <- cbind(testing.data[,predict.cols[predictor]], predict.NN)

png(paste0("images/logecoli_NN_",colnames(all.data)[predict.cols[predictor]],"_clean.png"), units="in", res=2000, width = 5, height = 4)
par(mar=c(3,3,2,8), mgp=c(1.75,.5,0))
plot(x = data2plot[,1], y = data2plot[,2]
     , xlim=c(min.val,max.val), ylim=c(min.val,max.val)
     , xlab="Actal", ylab="Predicted"
     , pch=20
     , main = stringr::str_replace_all(colnames(all.data)[predict.cols[predictor]], c("[.]" = " "))
)
abline(a=0,b=1,col="blue", lwd=2)

legend("bottomright", 
       inset = c(-.55,-.23),
       legend = c("Observation", "Perfect Fit", paste0("RMSE = ",round(RMSE.NN,2))),
       col = c("black", "blue", NA),
       pch = c(20,NA, NA),
       lwd = c(NA,2, NA),
       bty = "n",
       xpd=NA,
       xjust = 1,
       text.font = 2)

text(do.call(paste0, as.list(paste0(stringr::str_replace_all(predict.NN.colnames, c("[.][.]" = " ", "[.]" = " ")), "\n"))), x = max.val+max.val*.01, y = max.val-(max.val-min.val)/2, xpd=NA, pos=4, cex=.7)
dev.off()
}
```


```{r Solve for k}
all.data <- mergeData(list.x = list(oct.paa,vis.data))
all.data <- na.omit(all.data)
remove.cols.names <- c("PAA.Pump.Total.Flow", "PAA.Set.Point.Dose.Algorithm", "...10" , "Volume.to.1.min..Sample" , "Total.Basin.Volume", "SPBased.Disinfection.CT",     "CalcBased.Disinfection.CT", "CODto..V.","TSS..V.", "UVT..V.", "UVT..V.", "SACto..V.")
remove.cols <- sapply(remove.cols.names, function(x) which(colnames(all.data) == x))
all.data <- all.data[,-remove.cols]

# Repeat once with data to calculate k based on actual C2, then repeat with NN C2
t <- all.data[,"DT.of.1.2.Basin"]
C2 <- all.data[,"PAA...1.2.Basin.Sampling"]
C1 <- all.data[,"PAA...1.min..Sample"]
C0 <- all.data[,"Pump.Flow.Based.PAA.Dose"]

# Solve for k
k <- -(1/t)*log(C2/(C1))
plot(k)
k_avg <- mean(k)

# Calculate CT
Ct = C1/k*exp(-k*t)
Ct_kavg <- C1/k_avg*exp(-k_avg*t)
plot(Ct)
points(Ct_kavg)


# Ecoli data 
ecoli <- readxl::read_excel("data/PAA-Ecoli.xlsx", 
                                sheet = "Sheet2")
ecoli <- list(xts(na.omit(ecoli[,2][[1]]), order.by = na.omit(ecoli[,1][[1]])),
              xts(na.omit(ecoli[,4][[1]]), order.by = na.omit(ecoli[,3][[1]])))

ecoli <- mergeData(ecoli)
colnames(ecoli) <- c("Pre-dis E.coli", "Post-dis E.coli")

ecoli <- mergeData(list(ecoli, Ct_kavg))

N0 <- ecoli[,1]
N <- ecoli[,2]
Ct_ecoli <- ecoli[,3]

fn <- function(beta, k_d, k_p, N, N0, Ct) {
  N_calc = as.numeric(N0)*beta*exp(-as.numeric(Ct)*k_d)+as.numeric(N0)*(beta-1)*exp(-as.numeric(Ct)*k_p)
  # N_error
  return(xts(N_calc-N))
}
beta <- seq(0.9,1, by=(1-0.9)/length(N0)) 
k_d <- seq(0.2,0.5, by=(0.5-0.2)/length(beta)) 
k_p <- seq(0,0.2, by=0.2/length(beta))
N_error <- list()
N_index <- list()
for (i in 1:length(beta)) {
  for(j in 1:length(k_d)) {
    for(k in 1:length(k_p)) {
      for(l in 1:length(N0)) {
        N_error_iteration <- fn(beta = beta[i], 
                                     k_d = k_d[j], 
                                     k_p = k_p[k], 
                                     N0 = N0[l], 
                                     N = N[l], 
                                     Ct = Ct_ecoli[l])
        N_error <- c(N_error, list(N_error_iteration^2))
        N_index <- c(N_index, list(c(i,j,k,l)))
      }
    }
  }
}


N_error_compiled <- do.call(rbind, N_error)
N_index_compiled <- do.call(rbind, N_index)
sum.sq.error <- sapply(seq(1,length(N0), by = 1), function(x) sum(N_error_compiled[which(N_index_compiled[,4] == x),]))
which(N_index_compiled[,4] ==1)
min.sq.error <- which(min(sum.sq.error)==sum.sq.error)

N_index[[min.sq.error]]
beta.i <- beta[N_index[[1]]]
k_d.i <- k_d[N_index[2]]
k_p.i <- k_p[N_index[3]]
N0.i <- N0[N_index[4]]


# all.data <- vis.data
# data2 <- ecoli
# r <- paste0(range(index(all.data))[1],"/",range(index(all.data))[2])
# r <- paste0(range(index(data2[r]))[1],"/",
#             range(index(data2[r]))[2])
all.data <- mergeData(list.x = list(data2[r],all.data[r])) 




Ct <- Ct # Timestamp mismatch


```




```{r Manual NN, eval=FALSE, include=FALSE}
weights <- NN$weights[[1]][[1]][2:length(NN$weights[[1]][[1]])]
bias <- c(NN$weights[[1]][[1]][1], NN$weights[[1]][[2]][1])

# Input Layer
scaled <- testing.NN[,-predict.cols]
scaled.weighted <- sapply(1:ncol(scaled),function(x) scaled[,x] * weights[x])
scaled.weighted <- apply(scaled.weighted,1,sum)
scaled.weighted.biased <- scaled.weighted + bias[1]

# Layer 1
lay1.activation <- 1/(1+exp(-scaled.weighted.biased))
lay1.weighted <- lay1.activation*NN$weights[[1]][[2]][2]
lay1.weighted.biased <- lay1.activation+bias[2]

# Layer 2
lay2.activation <-1/(1+exp(-lay1.weighted.biased))


scaled.activated.weighted <- sapply(1:ncol(scaled.activated),function(x) scaled.activated[,x] * weights[x])
colnames(scaled.activated.weighted) <- colnames(scaled.activated)

# Hidden Layer 1
hidden.node.activated <- apply(scaled.activated.weighted,1, function(x) sum(x)+bias[1])
hidden.node.activated <- 1/(1+exp(-hidden.node.activated))
hidden.node.activated.weighted <- hidden.node.activated*NN$weights[[1]][[2]][2]

# Hidden Layer 2
hidden.node.activated.weighted <- hidden.node.activated.weighted + bias[2]
hidden.node.activated.weighted <- 1/(1+exp(-hidden.node.activated.weighted))

## Re-scale
predict.manual <- (hidden.node.activated.weighted * (max(all.data[,predict.cols[2]]) - min(all.data[,predict.cols[2]]))) + min(all.data[,predict.cols[2]])
```

