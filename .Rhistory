data.vars.count <- apply(data.vars,2,function(x)length(which(x)))
data.vars <- sapply(data.vars, function(x) grepl(x, data.top5[,1]))
data.vars.count <- apply(data.vars,2,function(x)length(which(x)))
View(data.vars.count)
barplot(data.vars.count)
barplot(data.vars.count[order(data.vars.count)])
barplot(data.vars.count[-order(data.vars.count)])
barplot(data.vars.count[order(-data.vars.count)])
data.nodes.count <- sapply(unique(data.top5$Nodes), function(x) length(which(data.top5$Nodes == x)))
View(data.nodes.count)
rownames(data.nodes.count) <- unique(data.top5$Nodes)
names(data.nodes.count) <- unique(data.top5$Nodes)
x.combos
names(data.nodes.count)
names(data.nodes.count) <- x.combos
data.top5 <- subset(data, r2 > quantile(r2, prob = 1 - 1/100))
data.vars <- colnames(all.data)
data.vars <- sapply(data.vars, function(x) grepl(x, data.top5[,1]))
data.vars.count <- apply(data.vars,2,function(x)length(which(x)))
data.nodes.count <- sapply(unique(data.top5$Nodes), function(x) length(which(data.top5$Nodes == x)))
names(data.nodes.count) <- x.combos
data.top5 <- subset(data, r2 > quantile(r2, prob = 1 - 1/100))
data.vars <- colnames(all.data)
data.vars <- sapply(data.vars, function(x) grepl(x, data.top5[,1]))
data.vars.count <- apply(data.vars,2,function(x)length(which(x)))
data.nodes.count <- sapply(unique(data.top5$Nodes), function(x) length(which(data.top5$Nodes == x)))
names(data.nodes.count) <- unique(data.top5$Nodes)
x.count
x.combos
## Find optimum number of variables
n <- which(colnames(all.data) != predict.col.name)
x.combos <- c(7,8,10,11)
for(no.vars in x.combos) {
x <- data.frame(combn(n,no.vars))
x.index <- seq(1:ncol(x))
# detect cores with parallel() package
nCores <- detectCores(logical = FALSE)
# detect threads with parallel()
nThreads<- detectCores(logical = TRUE)
# Create doSNOW compute cluster
cluster = makeCluster(nThreads, type = "SOCK")
class(cluster);
# register the cluster
registerDoSNOW(cluster)
results <- foreach::foreach(i = x.index, .combine = rbind) %dopar% {
fmla <- as.formula(paste0(colnames(all.data)[predict.column],"~",
paste(colnames(all.data)[x[,i]], collapse= "+")))
nodes <- round(no.vars/2)
NN <- neuralnet::neuralnet(fmla, training.NN, hidden = nodes, linear.output = FALSE)
## Predict using NN
predict.NN <-  tryCatch(neuralnet::compute(NN, testing.NN[,-predict.column]), error = function(e){})
if(is.null(predict.NN)){
RMSE.NN <- NA
r2.NN <- NA
} else {
predict.NN <- (predict.NN$net.result * (max(all.data[,predict.column]) - min(all.data[,predict.column]))) + min(all.data[,predict.column])
# Calculate Root Mean Square Error (RMSE)
RMSE.NN <- (sum((testing.data[,predict.column] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
# Calculate R-sq
r2.NN <- r.sq(raw=testing.data[,predict.column], fit = predict.NN)
}
data.frame("Fmla" = as.character(fmla[3]),
"RMSE" = RMSE.NN,
"r2" = r2.NN,
"Nodes" = nodes)
}
# stop cluster and remove clients
stopCluster(cluster)
# insert serial backend, otherwise error in repetetive tasks
registerDoSEQ()
# clean up a bit.
invisible(gc); remove(nCores); remove(nThreads); remove(cluster);
write.csv(results, paste0("results/PAA_1min_NN_",results[1,4],"nodes_",no.vars,"vars.csv"))
}
}
# ## Build best NN
# data <- do.call(merge, sapply(paste0("results/",list.files(path="results")), function(file) {
file <- paste0("results/",list.files(path="results"))
for(i in 1:length(file)){
raw <- read.csv(file[i], row.names=1, stringsAsFactors=FALSE)
if(i ==1) data <- raw
if(i != 1)data <- rbind(data,raw)
}
# ))
data.top5 <- subset(data, r2 > quantile(r2, prob = 1 - 1/100))
data.vars <- colnames(all.data)
data.vars <- sapply(data.vars, function(x) grepl(x, data.top5[,1]))
data.vars.count <- apply(data.vars,2,function(x)length(which(x)))
plot(data.vars.count)
barplot(data.vars.count)
barplot(data.vars.count[order(data.vars.count)])
View(data.vars.count)
data.vars.count <- cbind(data.vars.count, data.vars.count/sum(data.vars.count))
View(data.cars.count)
View(data.vars.count)
View(data.top5)
n <- which(colnames(all.data) != predict.col.name)
x.combos <- c(3,6,9,12,15)
x.combos <- c(7,8,10,11)
for(no.vars in x.combos) {
for(iteration in 1:10) {
x <- data.frame(combn(n,no.vars))
x.index <- seq(1:ncol(x))
# detect cores with parallel() package
nCores <- detectCores(logical = FALSE)
# detect threads with parallel()
nThreads<- detectCores(logical = TRUE)
# Create doSNOW compute cluster
cluster = makeCluster(nThreads, type = "SOCK")
class(cluster);
# register the cluster
registerDoSNOW(cluster)
results <- foreach::foreach(i = x.index, .combine = rbind) %dopar% {
fmla <- as.formula(paste0(colnames(all.data)[predict.column],"~",
paste(colnames(all.data)[x[,i]], collapse= "+")))
nodes <- round(no.vars/2)
NN <- neuralnet::neuralnet(fmla, training.NN, hidden = nodes, linear.output = FALSE)
## Predict using NN
predict.NN <-  tryCatch(neuralnet::compute(NN, testing.NN[,-predict.column]), error = function(e){})
if(is.null(predict.NN)){
RMSE.NN <- NA
r2.NN <- NA
} else {
predict.NN <- (predict.NN$net.result * (max(all.data[,predict.column]) - min(all.data[,predict.column]))) + min(all.data[,predict.column])
# Calculate Root Mean Square Error (RMSE)
RMSE.NN <- (sum((testing.data[,predict.column] - predict.NN)^2) / nrow(testing.data)) ^ 0.5
# Calculate R-sq
r2.NN <- r.sq(raw=testing.data[,predict.column], fit = predict.NN)
}
data.frame("Fmla" = as.character(fmla[3]),
"RMSE" = RMSE.NN,
"r2" = r2.NN,
"Nodes" = nodes)
}
# stop cluster and remove clients
stopCluster(cluster)
# insert serial backend, otherwise error in repetetive tasks
registerDoSEQ()
# clean up a bit.
invisible(gc); remove(nCores); remove(nThreads); remove(cluster);
write.csv(results, paste0("results/PAA_1min_NN_",results[1,4],"nodes_",no.vars,"vars_",iteration,".csv"))
}
}
}
install.packages(c("doSNOW", "neuralnet", "stringr"))
rm(list = ls())
# setwd("..")
# source("functions/r-sq.R")
r.sq <- function(raw,fit) {
# y <- raw
# y_bar <- mean(raw)
# y_hat <- fit
# r_sq <- sum((y_hat-y_bar)^2) / sum((y-y_bar)^2)
r_sq <- cor(raw,fit)^2
return(r_sq)
}
# setwd("GitHub")
# setwd("~/KNewhart/MWRD")
library(xts)
mergeData <- function(list.x, sort.by = 1, average = FALSE) {
library(xts)
all.data <- do.call(merge, list.x)
all.data.index <- which(!is.na(all.data[,sort.by]))
for(i in 1:(length(all.data.index)-1)) {
row.start <- all.data.index[i]
row.stop <- all.data.index[i+1]
if((row.stop-row.start) == 1) {
next
}
if(!average) data.locf <- na.locf(all.data[(row.start+1):row.stop,])
if(average) {
data.avg <- t(data.frame(sapply(all.data[(row.start+1):row.stop,], function(x) mean(na.omit(x)))))
rownames(data.avg) <- as.character(index(all.data)[row.stop])
}
if (!exists("new.data")) {
if(!average) new.data <- data.frame(data.locf[nrow(data.locf),])
if(average) new.data <- data.avg
}
if (exists("new.data")) {
if(!average) new.data <- rbind(new.data, data.frame(data.locf[nrow(data.locf),]))
if(average) new.data <- rbind(new.data, data.avg)
}
}
new.data <- na.omit(new.data)
na.fix <- which(!is.na(as.POSIXct(rownames(new.data), format = "%Y-%m-%d %H:%M:%S")))
new.data.xts <- xts(new.data[na.fix,], order.by = as.POSIXct(rownames(new.data)[na.fix], format = "%Y-%m-%d %H:%M:%S"))
return(new.data.xts)
}
##### PAA Process Data - Grab #####
delta <- intToUtf8(0x0394)
# Daily data
process.data <- readxl::read_excel("data/Copy of PAA Process Data Clean KN.xlsx",
sheet = "Process Data", skip = 1)
process.data <- process.data[-1,]
n.paa.grab <- xts::xts(apply(process.data[,c(12:17,19:27)], 2, function(x) as.numeric(x)), order.by =  as.POSIXct(as.data.frame(process.data[,18])[,1], format = "%Y-%m-%d %H:%M:%S"))
colnames(n.paa.grab) <- c("PAA Dosing Pump Total Flow (gpm)", #1
"PAA Dose (mg/L)", #2
"PAA Setpoint (mg/L)", #3
"Upstream  Residual (mg/L)", #4
# paste0(delta,"PAA (mg/L)"),	#5
"deltaPAA (mg/L)", #5
"Pre-Disinfection E. coli (MPN/100 mL)",  #6
"Effluent Discharge (MGD)", #7
"Contact Tank Volume (MG)", #8
"Detention Time (min)", #9
"Time to Upstream Sample Point (min)", #10
"Log Removal (N0/N)", #11
"Effluent E. coli (MPN/100 mL)", #12
"CT (mg/L*min)", #13
"CuT (mg/L*min)", #14
"Ambient Temperature")#15
colnames(n.paa.grab) <- stringr::str_replace_all(colnames(n.paa.grab), c(" " = ".", "/" = "." , "-" = "","[(]" = "", "[)]" = "", "[*]"="."))
rm(process.data)
##### October PAA Process Data - Grab #####
oct.paa <- readxl::read_excel("data/Copy of PAA Process Data Clean KN.xlsx",
sheet = "Oct 2 to 15, 2018", range = "A1:V170")[-1,]
n.datetime <- which(colnames(oct.paa) == "Date and Time")
oct.paa.index <- oct.paa[,n.datetime]
oct.paa <- sapply(oct.paa[,-n.datetime], function(x) as.numeric(x))
colnames(oct.paa) <- stringr::str_replace_all(colnames(oct.paa), c(" " = "." , "-" = "" ))
oct.paa <- xts(oct.paa, order.by = oct.paa.index[[1]])
###### North Carbovis Data #####
vis.data <- readxl::read_excel("data/NNE Carbovis Data2.xlsx",
sheet = "Inst DL Data", col_types = c("date",
"text", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "skip", "numeric", "skip",
"skip", "skip", "numeric", "skip",
"skip", "skip", "skip", "numeric",
"skip", "skip", "skip", "numeric",
"skip"), skip = 6)
vis.data <- vis.data[which(vis.data[,2] == "Valid"),-2]
colnames(vis.data) <- c("Time", "CODto (mg/L)", "CODto (V)",
"TSS (mg/L)", "TSS (V)",
"UVT (%)", "UVT (V)",
"CODds (mg/L)", "CODds (V)",
"SACto (1/m)", "SACto (V)")
vis.data <- xts(vis.data[,-1], order.by = as.POSIXct(as.data.frame(vis.data[,1])[,1], format = "%Y-%m-%d %H-%M-%S"))
##### North Secondary - Online #####
## North secondary online
nsec.online <- as.data.frame(suppressWarnings(readxl::read_excel("data/North Secondary and Disinfection Process Data_20190215.xlsx", sheet = "NSEC Online Data", col_names = FALSE,
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"),
skip = 4)))
Optimize <- FALSE
if(Optimize){
predict.col.name <- c("PAA...1.min..Sample", "PAA...1.2.Basin.Sampling")
percent.train = 0.8
training.index = NULL
all.data <- all.data[,which(colnames(all.data) != predict.col.name[2])]
predict.col.name <- predict.col.name[1]
iterations <- 10
obs <- 50
predict.col.name <- c("PAA...1.min..Sample")
## Prep data
predict.column <- which(colnames(all.data) == predict.col.name)
rm(list = ls())
# setwd("..")
# source("functions/r-sq.R")
r.sq <- function(raw,fit) {
# y <- raw
# y_bar <- mean(raw)
# y_hat <- fit
# r_sq <- sum((y_hat-y_bar)^2) / sum((y-y_bar)^2)
r_sq <- cor(raw,fit)^2
return(r_sq)
}
# setwd("GitHub")
# setwd("~/KNewhart/MWRD")
library(xts)
mergeData <- function(list.x, sort.by = 1, average = FALSE) {
library(xts)
all.data <- do.call(merge, list.x)
all.data.index <- which(!is.na(all.data[,sort.by]))
for(i in 1:(length(all.data.index)-1)) {
row.start <- all.data.index[i]
row.stop <- all.data.index[i+1]
if((row.stop-row.start) == 1) {
next
}
if(!average) data.locf <- na.locf(all.data[(row.start+1):row.stop,])
if(average) {
data.avg <- t(data.frame(sapply(all.data[(row.start+1):row.stop,], function(x) mean(na.omit(x)))))
rownames(data.avg) <- as.character(index(all.data)[row.stop])
}
if (!exists("new.data")) {
if(!average) new.data <- data.frame(data.locf[nrow(data.locf),])
if(average) new.data <- data.avg
}
if (exists("new.data")) {
if(!average) new.data <- rbind(new.data, data.frame(data.locf[nrow(data.locf),]))
if(average) new.data <- rbind(new.data, data.avg)
}
}
new.data <- na.omit(new.data)
na.fix <- which(!is.na(as.POSIXct(rownames(new.data), format = "%Y-%m-%d %H:%M:%S")))
new.data.xts <- xts(new.data[na.fix,], order.by = as.POSIXct(rownames(new.data)[na.fix], format = "%Y-%m-%d %H:%M:%S"))
return(new.data.xts)
}
##### PAA Process Data - Grab #####
delta <- intToUtf8(0x0394)
# Daily data
process.data <- readxl::read_excel("data/Copy of PAA Process Data Clean KN.xlsx",
sheet = "Process Data", skip = 1)
process.data <- process.data[-1,]
n.paa.grab <- xts::xts(apply(process.data[,c(12:17,19:27)], 2, function(x) as.numeric(x)), order.by =  as.POSIXct(as.data.frame(process.data[,18])[,1], format = "%Y-%m-%d %H:%M:%S"))
colnames(n.paa.grab) <- c("PAA Dosing Pump Total Flow (gpm)", #1
"PAA Dose (mg/L)", #2
"PAA Setpoint (mg/L)", #3
"Upstream  Residual (mg/L)", #4
# paste0(delta,"PAA (mg/L)"),	#5
"deltaPAA (mg/L)", #5
"Pre-Disinfection E. coli (MPN/100 mL)",  #6
"Effluent Discharge (MGD)", #7
"Contact Tank Volume (MG)", #8
"Detention Time (min)", #9
"Time to Upstream Sample Point (min)", #10
"Log Removal (N0/N)", #11
"Effluent E. coli (MPN/100 mL)", #12
"CT (mg/L*min)", #13
"CuT (mg/L*min)", #14
"Ambient Temperature")#15
colnames(n.paa.grab) <- stringr::str_replace_all(colnames(n.paa.grab), c(" " = ".", "/" = "." , "-" = "","[(]" = "", "[)]" = "", "[*]"="."))
rm(process.data)
##### October PAA Process Data - Grab #####
oct.paa <- readxl::read_excel("data/Copy of PAA Process Data Clean KN.xlsx",
sheet = "Oct 2 to 15, 2018", range = "A1:V170")[-1,]
n.datetime <- which(colnames(oct.paa) == "Date and Time")
oct.paa.index <- oct.paa[,n.datetime]
oct.paa <- sapply(oct.paa[,-n.datetime], function(x) as.numeric(x))
colnames(oct.paa) <- stringr::str_replace_all(colnames(oct.paa), c(" " = "." , "-" = "" ))
oct.paa <- xts(oct.paa, order.by = oct.paa.index[[1]])
###### North Carbovis Data #####
vis.data <- readxl::read_excel("data/NNE Carbovis Data2.xlsx",
sheet = "Inst DL Data", col_types = c("date",
"text", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "skip", "numeric", "skip",
"skip", "skip", "numeric", "skip",
"skip", "skip", "skip", "numeric",
"skip", "skip", "skip", "numeric",
"skip"), skip = 6)
vis.data <- vis.data[which(vis.data[,2] == "Valid"),-2]
colnames(vis.data) <- c("Time", "CODto (mg/L)", "CODto (V)",
"TSS (mg/L)", "TSS (V)",
"UVT (%)", "UVT (V)",
"CODds (mg/L)", "CODds (V)",
"SACto (1/m)", "SACto (V)")
vis.data <- xts(vis.data[,-1], order.by = as.POSIXct(as.data.frame(vis.data[,1])[,1], format = "%Y-%m-%d %H-%M-%S"))
##### North Secondary - Online #####
## North secondary online
nsec.online <- as.data.frame(suppressWarnings(readxl::read_excel("data/North Secondary and Disinfection Process Data_20190215.xlsx", sheet = "NSEC Online Data", col_names = FALSE,
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"),
skip = 4)))
all.data
rm(list = ls())
# setwd("..")
# source("functions/r-sq.R")
r.sq <- function(raw,fit) {
# y <- raw
# y_bar <- mean(raw)
# y_hat <- fit
# r_sq <- sum((y_hat-y_bar)^2) / sum((y-y_bar)^2)
r_sq <- cor(raw,fit)^2
return(r_sq)
}
# setwd("GitHub")
# setwd("~/KNewhart/MWRD")
library(xts)
mergeData <- function(list.x, sort.by = 1, average = FALSE) {
library(xts)
all.data <- do.call(merge, list.x)
all.data.index <- which(!is.na(all.data[,sort.by]))
for(i in 1:(length(all.data.index)-1)) {
row.start <- all.data.index[i]
row.stop <- all.data.index[i+1]
if((row.stop-row.start) == 1) {
next
}
if(!average) data.locf <- na.locf(all.data[(row.start+1):row.stop,])
if(average) {
data.avg <- t(data.frame(sapply(all.data[(row.start+1):row.stop,], function(x) mean(na.omit(x)))))
rownames(data.avg) <- as.character(index(all.data)[row.stop])
}
if (!exists("new.data")) {
if(!average) new.data <- data.frame(data.locf[nrow(data.locf),])
if(average) new.data <- data.avg
}
if (exists("new.data")) {
if(!average) new.data <- rbind(new.data, data.frame(data.locf[nrow(data.locf),]))
if(average) new.data <- rbind(new.data, data.avg)
}
}
new.data <- na.omit(new.data)
na.fix <- which(!is.na(as.POSIXct(rownames(new.data), format = "%Y-%m-%d %H:%M:%S")))
new.data.xts <- xts(new.data[na.fix,], order.by = as.POSIXct(rownames(new.data)[na.fix], format = "%Y-%m-%d %H:%M:%S"))
return(new.data.xts)
}
##### PAA Process Data - Grab #####
delta <- intToUtf8(0x0394)
# Daily data
process.data <- readxl::read_excel("data/Copy of PAA Process Data Clean KN.xlsx",
sheet = "Process Data", skip = 1)
process.data <- process.data[-1,]
n.paa.grab <- xts::xts(apply(process.data[,c(12:17,19:27)], 2, function(x) as.numeric(x)), order.by =  as.POSIXct(as.data.frame(process.data[,18])[,1], format = "%Y-%m-%d %H:%M:%S"))
colnames(n.paa.grab) <- c("PAA Dosing Pump Total Flow (gpm)", #1
"PAA Dose (mg/L)", #2
"PAA Setpoint (mg/L)", #3
"Upstream  Residual (mg/L)", #4
# paste0(delta,"PAA (mg/L)"),	#5
"deltaPAA (mg/L)", #5
"Pre-Disinfection E. coli (MPN/100 mL)",  #6
"Effluent Discharge (MGD)", #7
"Contact Tank Volume (MG)", #8
"Detention Time (min)", #9
"Time to Upstream Sample Point (min)", #10
"Log Removal (N0/N)", #11
"Effluent E. coli (MPN/100 mL)", #12
"CT (mg/L*min)", #13
"CuT (mg/L*min)", #14
"Ambient Temperature")#15
colnames(n.paa.grab) <- stringr::str_replace_all(colnames(n.paa.grab), c(" " = ".", "/" = "." , "-" = "","[(]" = "", "[)]" = "", "[*]"="."))
rm(process.data)
##### October PAA Process Data - Grab #####
oct.paa <- readxl::read_excel("data/Copy of PAA Process Data Clean KN.xlsx",
sheet = "Oct 2 to 15, 2018", range = "A1:V170")[-1,]
n.datetime <- which(colnames(oct.paa) == "Date and Time")
oct.paa.index <- oct.paa[,n.datetime]
oct.paa <- sapply(oct.paa[,-n.datetime], function(x) as.numeric(x))
colnames(oct.paa) <- stringr::str_replace_all(colnames(oct.paa), c(" " = "." , "-" = "" ))
oct.paa <- xts(oct.paa, order.by = oct.paa.index[[1]])
###### North Carbovis Data #####
vis.data <- readxl::read_excel("data/NNE Carbovis Data2.xlsx",
sheet = "Inst DL Data", col_types = c("date",
"text", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "numeric", "skip", "skip",
"skip", "skip", "numeric", "skip",
"skip", "skip", "numeric", "skip",
"skip", "skip", "skip", "numeric",
"skip", "skip", "skip", "numeric",
"skip"), skip = 6)
vis.data <- vis.data[which(vis.data[,2] == "Valid"),-2]
colnames(vis.data) <- c("Time", "CODto (mg/L)", "CODto (V)",
"TSS (mg/L)", "TSS (V)",
"UVT (%)", "UVT (V)",
"CODds (mg/L)", "CODds (V)",
"SACto (1/m)", "SACto (V)")
vis.data <- xts(vis.data[,-1], order.by = as.POSIXct(as.data.frame(vis.data[,1])[,1], format = "%Y-%m-%d %H-%M-%S"))
##### North Secondary - Online #####
## North secondary online
nsec.online <- as.data.frame(suppressWarnings(readxl::read_excel("data/North Secondary and Disinfection Process Data_20190215.xlsx", sheet = "NSEC Online Data", col_names = FALSE,
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"),
skip = 4)))
##### North Secondary - Online #####
## North secondary online
nsec.online <- as.data.frame(readxl::read_excel("data/North Secondary and Disinfection Process Data_20190215.xlsx", sheet = "NSEC Online Data"))
View(nsec.online)
##### North Secondary - Online #####
## North secondary online
nsec.online <- as.data.frame(readxl::read_excel("data/North Secondary and Disinfection Process Data_20190215.xlsx", sheet = "NSEC Online Data"), col_names=FALSE)
##### North Secondary - Online #####
## North secondary online
nsec.online <- as.data.frame(readxl::read_excel("data/North Secondary and Disinfection Process Data_20190215.xlsx", sheet = "NSEC Online Data"), col_names=FALSE, skip=4)
View(nsec.online)
##### North Secondary - Online #####
## North secondary online
nsec.online <- as.data.frame(readxl::read_excel("data/North Secondary and Disinfection Process Data_20190215.xlsx", sheet = "NSEC Online Data"), col_names=FALSE)
View(nsec.online)
